<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Class 3a: Review of concepts in Probability and Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Business Forecasting" />
    <script src="libs/header-attrs-2.27/header-attrs.js"></script>
    <link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
    <link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding-0.33/datatables.js"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Class 3a: Review of concepts in Probability and Statistics
]
.author[
### Business Forecasting
]

---

&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 20px;
}


&lt;/style&gt;







---
## Roadmap

### Last set of classess
- Types of data
- How to describe data
  - With visualizations
  - With summary statistics

--

### This set of classes
- How to evaluate estimators
- How to build confidence intervals
- How to test hypothesis

---

### Motivating Example

1. You run a bunch of Airbnbs

--
2. Should you invest more in cleaning?

--
3. Can you get higher price if your cleanliness score exceeds 4.5?

--
4. Get a sample of listings and compare the price of 
 - Those with cleanliness score below 4.5 (dirty) 
 - and above 4.5 (clean)

<div class="datatables html-widget html-fill-item" id="htmlwidget-1f2cdd7870e4a2136e61" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1f2cdd7870e4a2136e61">{"x":{"filter":"none","vertical":false,"fillContainer":false,"data":[["40032982","21962322","41841538","624813934659858771","47030021","46736994","43835384","559373490224130231","35128368","43833531","30229115","633954885193290889","574089316326042003","690075641782547793","9410423","21308302","25980248","6130916","52549421","558783222064955946","43833230","20536551","41584381","661539982266924598","54214447","41285785","43133053","682140193308936048","49715955","17880682","662861909053481312","50416464","14067654","529868024555129029","52738199","10191903","556527153850032441","43406289","52466672","48363982","50552074","42157781","610405740311102083","685461650997371552","45450842","577056908603484824","53795858","50942468","40089748","39632539","46382262","48316700","39371027","53826987","26164866","675999851420034625","45367370","591846768248257887","51467262","27779654","31316765","32596520","34841342","48385052","53298655","27825203","24799913","7497326","49244654","598698575046941082","688549735334165347","35430447","48069590","20456127","50508282","50342102","52126906","671234251056395329","22117912","634189553968832354","53829698","31851153","54197983","47991720","38404040","45687875","22247072","680256351616927591","47307457","54069071","21448160","669598945830229104","35114896","39127840","22790882","678378128971023324","38161229","592876320173232234","615073832400669762","38639644","19109580","677511627014749651","51888877","53739335","605096802057937100","454693","34568956","40990973","46200928","36422535","50919112","16290948","46057479","45804504","16732158","44844425","619489082677241308","27728036","10576847","27702514","51946747","20266388","31597750","39368238","52145452","52588620","37207688","41397000","621813066958551140","11553675","54073495","19382235","665841611666040077","30148929","53417737","567979455734280105","44330021","21204387","18293393","9465288","45994315","47034988","43206686","603841462689906413","52977322","40532942","21728742","35644643","36313624","36980999","20069705","25008119","52656654","49998025","53068599","43709987","16661511","9315338","45165329","33254148","554897217488213426","650193094530808918","41410912","54332747","38983813","515927973075176969","50565568","43703892","572023920388897424","51404831","42929613","40010746","53936586","51311517","27962278","40787070","22910103","44940946","7687977","15721334","38456572","23957804","44464420","18754486","51110043","30452635","40728445","40067597","48439142","20386531","34906096","19616579","36039157","4846536","37280274","42436964","49879390","42377927","24183514","15247095"],[3,4.5,4.5,3.4,4.29,4.29,4.43,4.46,4.4,3,4.39,4.42,3,4.33,4.37,1,4.5,4.25,4.42,4.41,3,4.5,4,4.38,3,4,4.42,4.44,4,4.48,4.35,4.5,4.17,3,4.5,3.89,4.4,4.35,3,4,4.5,4.2,4.29,3.5,4.33,4,4.5,4,4.17,4,4,4.5,3.9,4.5,4.38,4,4.5,4.26,4.5,4.5,4.5,4.47,3.6,4,3,4.39,1,4.47,4.33,3,4.5,4.5,4.33,2,4.46,4.47,4.19,4.22,1,4.5,4,1,4.06,4.27,4.46,4,4.42,4.21,3,3.67,4.5,4.5,3.89,4,4,4.27,4,4.5,1,4.48,4.85,5,4.96,5,5,4.94,4.96,4.94,4.94,4.8,4.84,4.78,4.67,4.93,4.73,4.95,4.75,4.67,4.89,4.96,4.8,4.69,4.94,4.92,4.72,4.85,4.82,4.7,4.84,4.81,4.91,4.79,4.97,4.89,5,4.92,5,4.95,4.91,5,5,4.64,5,4.89,5,4.84,4.94,4.83,4.62,4.98,4.7,4.86,5,4.67,4.65,4.8,5,5,4.88,4.89,4.73,4.88,4.86,4.89,4.78,5,4.7,4.85,4.98,4.76,5,5,5,4.82,4.87,4.73,4.72,5,4.64,4.71,4.86,4.89,4.78,4.96,4.79,4.85,4.72,4.99,5,4.8,4.77,4.85,5,4.58,5,4.88,4.88,4.8,5,4.95],[1023,4500,380,1350,684,451,617,657,1452,463,463,1776,999,550,1183,598,500,350,1058,600,463,2137,513,771,599,400,342,1368,1100,400,941,850,390,179,1436,240,348,555,3757,700,942,900,290,2500,2133,400,266,550,600,270,275,900,504,1600,1416,1121,845,794,300,1199,300,676,800,690,1900,580,764,890,326,1680,1371,550,1837,350,467,1500,300,220,450,687,499,220,370,551,1500,950,589,369,220,468,999,1560,300,1996,415,635,900,686,1500,857,1228,1978,1662,700,1200,1319,300,1876,1849,1000,593,800,686,1180,650,985,2050,325,882,716,1249,723,1500,791,1669,1009,713,850,4075,933,1100,257,3810,768,729,731,1905,4276,380,536,1000,2162,3763,1075,1422,878,890,709,1184,1080,1400,2314,470,2215,629,900,1390,350,789,480,1123,350,1258,1350,1889,891,1750,997,1347,1035,2300,450,1300,438,370,534,800,300,668,1249,850,1990,280,2942,481,820,540,2121,6200,2800,916,862,309,1500,428,823,2000,1799,200,1200],["Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Dirty","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean","Clean"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>id<\/th>\n      <th>review_scores_cleanliness<\/th>\n      <th>price<\/th>\n      <th>clean<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"searching":false,"initComplete":"function(settings, json) {\n$(this.api().table().container()).css({'font-size': '12px'});\n}","columnDefs":[{"className":"dt-right","targets":[1,2]},{"name":"id","targets":0},{"name":"review_scores_cleanliness","targets":1},{"name":"price","targets":2},{"name":"clean","targets":3}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.initComplete"],"jsHooks":[]}</script>

---
 
### Motivating example

In statistical language: 
- .blue[Population]: Entire group we want to learn about, impossible to assess directly

--
  - All listings of Airbnb in Mexico City
  - Ideally we would like to know the entire distribution of prices
  
--

- .blue[Parameters]: Number describing a characteristic of the population

--
  - We want to know mean price of clean `\(\mu_c\)` and dirty `\(\mu_d\)` apartments 
  
--

- .blue[Sample]: Part of the population we have data for

--
  - We have a sample of 200 listings
  
--

- .blue[Goal]: What we want to learn about the population?
  - Is `\(\mu_c\)` &gt; `\(\mu_d\)`? If yes, by how much?
  - But we do not know `\(\mu_c\)` and `\(\mu_d\)`
  - We will try to guess it using an estimator and a random IID sample

---



### What is a random sample?

- **At random:** A sample is random if each member of the population (each listing) has an equal chance of being selected. This process of selecting is called *drawing* from a population or a sample.

--
- **Random Variable: `\(P_i\)`:**
  - Random variable describing the observation `\(i\)`. Before drawing the sample, we don't know its value: it could be any price from the distribution.

--
- **Random Sample** is a collection of random variables `\(\{P_1, P_2,...,P_n\}\)`

--
- **Observed Value: `\(p_i\)`:**
  - Once we observe a specific outcome for the random variable, it becomes a realized value, or `\(p_i\)`. It's no longer a random variable but a constant from our sample.


#### Before Drawing the Sample


|                                       |     |     |     |     |     |     |     |     |
|:-------------------------------------:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| Random Variables P_i (Before Drawing) | P_1 | P_2 | P_3 | P_4 | P_5 | P_6 | P_7 | P_8 |
|         Selected Listings IDs         |     |     |     |     |     |     |     |     |
|  Realized Values p_i (After Drawing)  |     |     |     |     |     |     |     |     |
---



### What is a random sample?


- **Random Variable: `\(P_i\)`:**
  - Random variable describing the observation `\(i\)`. Before drawing the sample, we don't know its value: it could be any price from the distribution.


- **Random Sample** is a collection of random variables `\(\{P_1, P_2,...,P_n\}\)`


- **Observed Value: `\(p_i\)`:**
  - Once we observe a specific outcome for the random variable, it becomes a realized value, or `\(p_i\)`. It's no longer a random variable but a constant from our sample.

#### After Drawing the Sample (Sample 1)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 8451 | 9015 | 8161 | 9085 | 8268 | 1622 | 1933 | 3947 |
|  Realized Values p_i (After Drawing)  | 120  | 150  | 800  | 200  | 1400 | 110  | 1800 | 900  |
---



### What is a random sample?


- **Random Variable: `\(P_i\)`:**
  - Random variable describing the observation `\(i\)`. Before drawing the sample, we don't know its value: it could be any price from the distribution.


- **Random Sample** is a collection of random variables `\(\{P_1, P_2,...,P_n\}\)`


- **Observed Value: `\(p_i\)`:**
  - Once we observe a specific outcome for the random variable, it becomes a realized value, or `\(p_i\)`. It's no longer a random variable but a constant from our sample.

#### After Drawing the Sample (Sample 2)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 3145 | 3773 | 6721 | 3373 | 2102 | 5365 | 4453 | 3621 |
|  Realized Values p_i (After Drawing)  | 260  | 420  | 500  | 2120 | 800  | 1450 | 120  | 809  |
---

### What is a random sample?


- **Random Variable: `\(P_i\)`:**
  - Random variable describing the observation `\(i\)`. Before drawing the sample, we don't know its value: it could be any price from the distribution.


- **Random Sample** is a collection of random variables `\(\{P_1, P_2,...,P_n\}\)`


- **Observed Value: `\(p_i\)`:**
  - Once we observe a specific outcome for the random variable, it becomes a realized value, or `\(p_i\)`. It's no longer a random variable but a constant from our sample.

#### After Drawing the Sample (Sample 3)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 4971 | 2684 | 6331 | 3999 | 1995 | 4582 | 1478 | 1633 |
|  Realized Values p_i (After Drawing)  | 150  | 980  | 3450 | 220  | 120  | 853  | 2353 | 1244 |
---


### What is a random sample?



- **IID (Independent and Identically Distributed):**

--
  - **Independent:** The selection of one unit ( `\(P_i\)` ) doesn't affect the selection of another ( `\(P_j\)` )
  
--
  - **Identically Distributed:** All units `\(P_i\)` come from the same distribution.


---

### Estimators


- **Intuition**
  - It's our method of guessing the parameter based on the data we have
  - A function of random variables in our sample `\(\hat\theta=f(P_1, P_2,...,P_n)\)`
  - Given its random nature, we can analyze its statistical properties
  - Examples we have seen: 
      - `\(\hat{\mu_c}=\bar{P}=f(P_1, P_2,...,P_n)=\frac{\sum_n P_i}{n}\)`
      - `\(s_c=g(P_1, P_2,...,P_n)=\sqrt{\frac{1}{n-1} \sum^n_{i=1}(P_i-\bar{P})^2}\)`

--
  - It cannot contain any unknown quantities (like `\(\sigma\)` or `\(\mu_p\)`)  
  
--

- **Point Estimate:**
  - A single number computed from the realized sample data `\(\{p_1,p_2,...p_n\}\)`
      - `\(\bar{p}=f(p_1, p_2,...,p_n)=\frac{\sum_n p_i}{n}\)`
      - No longer random

---

### Example: Estimator

- Suppose we want to know average price of the apartment in Mexico City, but we don't have data for the whole population.

- We take a sample of 8 listings and calculate the average price.

#### Before Drawing the Sample


|                                       |     |     |     |     |     |     |     |     |
|:-------------------------------------:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| Random Variables P_i (Before Drawing) | P_1 | P_2 | P_3 | P_4 | P_5 | P_6 | P_7 | P_8 |
|         Selected Listings IDs         |     |     |     |     |     |     |     |     |
|  Realized Values p_i (After Drawing)  |     |     |     |     |     |     |     |     |

**Estimator:** `\(\hat\mu=\frac{P_1+P_2+P_3+P_4+P_5+P_6+P_7+P_8}{8}\)`



---



### Example: Estimator

- Suppose we want to know average price of the apartment in Mexico City, but we don't have data for the whole population.

- We take a sample of 8 listings and calculate the average price.

#### After Drawing the Sample (Sample 1)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 8451 | 9015 | 8161 | 9085 | 8268 | 1622 | 1933 | 3947 |
|  Realized Values p_i (After Drawing)  | 120  | 150  | 800  | 200  | 1400 | 110  | 1800 | 900  |


**Estimator:** `\(\hat\mu=\frac{P_1+P_2+P_3+P_4+P_5+P_6+P_7+P_8}{8}\)`

**Point estimate:** `\(\frac{p_1+p_2+p_3+p_4+p_5+p_6+p_7+p_8}{8}=685\)`

---

### Example: Estimator

- Suppose we want to know average price of the apartment in Mexico City, but we don't have data for the whole population.

- We take a sample of 8 listings and calculate the average price.

#### After Drawing the Sample (Sample 2)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 3145 | 3773 | 6721 | 3373 | 2102 | 5365 | 4453 | 3621 |
|  Realized Values p_i (After Drawing)  | 260  | 420  | 500  | 2120 | 800  | 1450 | 120  | 809  |


**Estimator:** `\(\hat\mu=\frac{P_1+P_2+P_3+P_4+P_5+P_6+P_7+P_8}{8}\)`

**Point estimate:** `\(\frac{p_1+p_2+p_3+p_4+p_5+p_6+p_7+p_8}{8}=809.875\)`

---

### Example: Estimator

- Suppose we want to know average price of the apartment in Mexico City, but we don't have data for the whole population.

- We take a sample of 8 listings and calculate the average price.

#### After Drawing the Sample (Sample 3)


|                                       |      |      |      |      |      |      |      |      |
|:-------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Random Variables P_i (Before Drawing) | P_1  | P_2  | P_3  | P_4  | P_5  | P_6  | P_7  | P_8  |
|         Selected Listings IDs         | 4971 | 2684 | 6331 | 3999 | 1995 | 4582 | 1478 | 1633 |
|  Realized Values p_i (After Drawing)  | 150  | 980  | 3450 | 220  | 120  | 853  | 2353 | 1244 |

**Estimator:** `\(\hat\mu=\frac{P_1+P_2+P_3+P_4+P_5+P_6+P_7+P_8}{8}\)`

**Point estimate:** `\(\frac{p_1+p_2+p_3+p_4+p_5+p_6+p_7+p_8}{8}=1171.25\)`

---

### Estimators 


- The mean price in our sample is `\(\bar{p}_c=\)` 1245.43 MXN
- This is our point estimate

--
- Can can't really say how close this one number (point estimate) is to the true mean price in Mexico City without knowing the population
- But we can say how good our method of guessing (estimator) is by looking at it's sampling distribution



---
### Estimators 

- **Sampling distribution** is the distribution of the estimator calculated from multiple random samples drawn from the same population.


&lt;iframe src="https://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm" width="100%" height="500px" data-external="1"&gt;&lt;/iframe&gt;

  
---


### Expectation of an estimator

- A good estimator should be unbiased:
`$$E[\hat{\theta}]=\theta$$` 
- Where `\(\theta\)` is some parameter and `\(\hat{\theta}\)` is its estimator
- This should be true for any value of `\(\theta\)`
- The sampling distribution should be centered at the parameter's value
- Intuitively, on average the estimator should give us the parameter's value
- When I take a many,many,many samples of apartments and calculate mean price in each sample
  - The average of these means should be super close to the true mean price in Mexico City


--
`$$Bias(\hat{\theta})=E[\hat{\theta}]-\theta$$`
- Bias of an estimator is a difference between its expectation and the parameter
- Lets look at a couple of estimators and check if they are biased or not

---

### Example 1: Estimator = 570
#### Expectation
- Consider some random variable `\(X_i\)` with unknown mean `\(E(X_i)=\mu\)`
- We want to estimate this mean
- The estimator: `\(\hat{\theta}_1 = 570\)`

--
- Expected Value: `\(E(\hat{\theta}_1) = 570\)`

--
- Bias: `\(E(\hat{\theta}_1)-\mu\neq 0\)` if `\(\mu \neq 570\)` (biased)

---

### Example 2: Estimator = `\(X_i\)`
#### Expectation
- Consider some random variable `\(X_i\)` with unknown mean `\(E(X_i)=\mu\)`
- We want to estimate this mean
- The estimator: `\(\hat{\theta}_2 = X_i\)`

--
- Expected Value: `\(E(\hat{\theta}_2) = E(X_i) = \mu\)`

--
- Bias: `\(E(\hat{\theta}_2) - \mu=0\)` (unbiased)

--
- Is it a good estimator?
---

### Example 3: Estimator = `\((3X_1 + X_2)/5\)`
#### Expectation
- Consider some random variable `\(X_i\)` with unknown mean `\(E(X_i)=\mu\)`
- We want to estimate this mean
- The estimator: `\(\hat{\theta}_3 = \frac{3X_1 + X_2}{5}\)`

--
- Expected Value: `\(E(\hat{\theta}_3)= \frac{3}{5}E(X_1) + \frac{1}{5}E(X_2) = \frac{3}{5}\mu + \frac{1}{5}\mu = \frac{4}{5}\mu\)`

--
- Bias: `\(E(\hat{\theta}_3) - \mu= \frac{4}{5}\mu - \mu=-\frac{1}{5}\mu\)` (biased)

---
### Example 4: Estimator = `\(\frac{\sum{X_i}}{n}\)`
#### Expectation
- Consider some random variable `\(X_i\)` with unknown mean `\(E(X_i)=\mu\)`
- We want to estimate this mean
- The estimator: `\(\hat{\theta}_4 = \frac{\sum_n{X_i}}{n}\)`

--
- Expected Value: `\(E(\hat{\theta}_4)=E(\frac{\sum_n{X_i}}{n})=\frac{\sum_n{E(X_i)}}{n}=\frac{\sum_n{\mu}}{n} = \mu\)`

--
- Bias: `\(E(\hat{\theta}_4) - \mu=0\)` (unbiased)

---

### Variance of the estimator

- Good estimator is unbiased
- But how do we choose among unbiased estimator?

--
  - Suppose we sample IID from `\(\small X \sim \mathcal{N}(\mu=10, \sigma=10)\)`
  - Imagine you don't know the mean is 10, and you try to estimate it:
  - Estimator 1:  `\(\hat\mu_1=\small (3X_1 + X_2)/4\)`
  - Estimator 2:  `\(\hat\mu_2=\small (X_1 + X_2+X_3+X_4)/4\)`
  - An estimator is more `\(\textbf{efficient}\)` if it has a smaller variance

--
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-10-2.png" width="100%" /&gt;




---
### Variance of the estimator

- Variance of an estimator is defined as:

`$$Var(\hat{\theta})=E[(\hat{\theta}-E[\hat\theta])^2]$$`
- We want the estimator to have low  variance! 
- Estimator with the lower variance is more efficient
- In the example above

`$$var(\hat\mu_1)=var(\frac{3X_1 + X_2}{4})&gt;var(\frac{X_1+X_2+X_3+X_4}{4})=var(\hat\mu_2)$$`
- Relative efficiency of the two estimators is the ratio of their variances
`$$Eff_{\hat\mu_1,\hat\mu_2}=\frac{var(\frac{3X_1 + X_2}{4})}{var(\frac{X_1+X_2+X_3+X_4}{4})}=\frac{\frac{10}{16}}{\frac{4}{16}}=\frac{5}{2}$$`

---

### Variance of estimators

####Example 1: Estimator = 570
-  `\(\small Var(\hat{\theta}_1) = E[(\hat{\theta}_1 - E[\hat{\theta}_1])^2]=E[(570 - E[570])^2] = 0\)`

--
#### Example 2: Estimator = `\(X_i\)`
- `\(\small  Var(\hat{\theta}_2) = E[(X_i - \mu)^2]=\sigma^2\)`

--
#### Example 4: Estimator = `\(\frac{\sum{X_i}}{n}\)`
- `\(\small  Var(\hat{\theta}_4) = E\left[\left(\frac{\sum{X_i}}{n} - \mu\right)^2\right]=\frac{\sigma^2}{n}\)`

--
#### Example 3: Estimator = `\(\frac{3X_1 + X_2}{4}\)`
- `\(\small  Var(\hat{\theta}_4) = E\left[\left((3X_1 + X_2)/4 - \mu\right)^2\right]=\frac{10\sigma^2}{16}\)`


---

### Side note

- In all previous cases of estimators we assumed an independent sample

- Suppose that `\(X_1\)` and `\(X_2\)` are **not independent**
- Example: daily sales of two products in the same store 

--
- What is `\(E(X_1+X_2)\)`

--
- What is `\(var(X_1+X_2)\)`?

--
- What about `\(var(X_1-X_2)\)`?


---

### Biased Estimator = `\(s_b^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n}\)`
- Consider the estimator: `\(\hat{\theta}_6 = s_b^2\)`
- We are trying to estimate `\(\sigma^2\)`

--
`$$E[\hat{\theta}_6] = E[s_b^2]= E[\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n}]=\frac{(n - 1)\sigma^2}{n}$$`

--
- So: 

`$$Bias(\hat{\theta}_6)=E[\hat{\theta}_6]-\sigma^2=-\frac{\sigma^2}{n}$$`

--
- We are underestimating the variance

--
- The sample variance estimator (divided by `\(\frac{1}{n-1}\)`) is unbiased:

`$$E[\hat{\theta}_7] = E[s^2]= E[\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}]=\frac{(n - 1)\sigma^2}{n-1}=\sigma^2$$`


---
### Mean Squared Error

***Mean Squared Error*** (MSE) is a summary measure of how good an estimator is:

`$$MSE(\hat{\theta})=E[(\hat{\theta}-\theta)^2]$$`
- The lower MSE, the better the estimator


--
- It summarizes both the bias and the variance:

`\begin{align*}
\small MSE(\hat{\theta})&amp;=E[(\hat{\theta}-\theta)^2] \\
&amp; =E[(\hat{\theta}-E(\hat{\theta})+E(\hat{\theta})-\theta)^2]\\
&amp;= E[(\hat{\theta} - E(\hat{\theta}))^2 + 2(\hat{\theta} - E(\hat{\theta}))(E(\hat{\theta}) - \theta) + (E(\hat{\theta}) - \theta)^2] \\
&amp;= E[(\hat{\theta} - E(\hat{\theta}))^2] + E[2(\hat{\theta} - E(\hat{\theta}))(E(\hat{\theta}) - \theta)] + E[(E(\hat{\theta}) - \theta)^2] \\
&amp;= E[(\hat{\theta} - E(\hat{\theta}))^2] + 2(\underbrace{E[\hat{\theta} - E(\hat{\theta})]}_{=0})(E(\hat{\theta}) - \theta) + E[(E(\hat{\theta}) - \theta)^2] \\
&amp;= \text{var}(\hat{\theta}) + \text{Bias}(\hat{\theta})^2
\end{align*}`


--
- If estimator is unbiased, then `$$MSE(\hat{\theta})=\text{var}(\hat{\theta})$$`
---

### Trading Bias for Variance

- Suppose you want to estimate customer's income to know who to target.
- Red line shows the true value
- Which of the estimators would you prefer?

&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-11-1.png" width="100%" /&gt;


---
### Mean Squared Error of sample mean (optional)

-  `\(\frac{3X_1 + X_2}{4}\)` is worse than `\(\frac{X_1+X_2}{2}\)`?

--
- Both estimators have the form of  `\(\hat{\theta}=\sum_n c_iX_i\)` with `\(n=2\)`
  - They have different weights `\(c_i\)` or in vector form `\(\mathbf{c}=\{c_1,c_2,..c_n\}\)`, with `\(\sum_ic_i=1\)`
  
--
- Sample mean is the best because for any n and `\(\mathbf{c}\)` such that `\(\sum_ic_i=1\)`:
`$$argmin_{\mathbf{c}}\underbrace{E[(\sum_n c_iX_i-\mu)^2]}_{MSE}=\{\frac{1}{n},\frac{1}{n},..\frac{1}{n}\}$$`


---

### Mean Squared Error of sample mean (optional)


And hence
`$$min_{\mathbf{c}}\underbrace{E[(\sum_n c_iX_i-\mu)^2]}_{MSE}=E[(\frac{\sum_n X_i}{n}-\mu)^2]$$`
- That is, for any estimator of `\(\mu\)` of the form `\(\hat{\theta}=\sum_n c_iX_i\)`, sample mean has the lowest MSE!
  - Having different `\(c_i\)` than `\(\frac{1}{n}\)` would increase the MSE
  
 
---
### Sampling Distribution

- We know how to determine the mean and the variance of the estimator
- Can we say anything about the distribution of the estimator?

--
- In case of sample mean, yes!

--
- That's what **Central Limit Theorem** is about, the most exciting theorem in statistcs!

---

### Central Limit Theorem 

- Suppose `\(X_1,X_2,...,X_n\)` are **i.i.d** variables drawn **at random** from a distribution with mean `\(\mu\)` and standard deviation `\(\sigma\)`

- Let `\(S_n=\sum_nX_n\)`. 
  
--
  - Note that: `\(E[S_n]=n\mu\)` and `\(st.dev.(S_n)=\sqrt{n}\sigma\)`

--
- Let `\(\bar{X}_n=\frac{\sum_nX_n}{n}\)` 

--
  - Note that: `\(E[\bar{X}_n]=\mu\)` and `\(st.dev.(\bar{X}_n)=\frac{\sigma}{\sqrt{n}}\)`

--
- Let `\(Z_n=\frac{\bar{X}_n-\mu}{\frac{\sigma}{\sqrt{n}}}\)`
  
--
  - Note that: `\(E[Z_n]=0\)` and `\(st.dev.(Z_n)=1\)`

--
- **Central Limit Theorem** says that **for large n**:

`$$S_n \sim \mathcal{N}(n\mu,\underbrace{\sqrt n \sigma}_{st.dev.}) \qquad\text{and}\qquad \bar{X}_n \sim \mathcal{N}(\mu,\frac{\sigma}{\sqrt n}) \qquad\text{and}\qquad \bar{Z}_n \sim \mathcal{N}(0,1)$$`
- In large samples, sample mean is normally distributed with mean `\(\mu\)` and st. dev. `\(\frac{\sigma}{\sqrt{n}}\)` 

---
- The original distribution of `\(X_i\)` does not matter (but outliers make convergence longer)
- Larger **n**, tighter distribution around the mean 
- Smaller ** `\(\sigma\)` **, tighter distribution around the mean 
&lt;iframe src="https://seeing-theory.brown.edu/probability-distributions/index.html#section3" width="100%" height="450px" data-external="1"&gt;&lt;/iframe&gt;
Source: [https://seeing-theory.brown.edu/probability-distributions/index.html#section3)


---
What if it's a discrete variable?
- Let `\(X_i\sim \text{Bernoulli}(p=0.5)\)`. Here is the distribution of `\(\bar{X}_n\)`:
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-12-2.png" width="100%" /&gt;
- What is the standard deviation?

--
- `\(\sigma_{\bar{X}}=\sqrt{var(\bar{X}_n)}=\frac{\sigma_X}{\sqrt n}=\frac{\sqrt{p(1-p)}}{\sqrt n}=\frac{0.5}{\sqrt n}\)`


---


### Central Limit Theorem 
What happens if some assumptions are not respected?
- .blue[Random draws] means that each member of the population has equal chance of being selected 
- Keep in mind that some values occur more often in the population than others
- More members with this value - higher chance of this value being sampled

--

**Example**
- Imagine you are evaluating a new skincare product to determine how people like it (on scale 1-5)
- However, you can only access online reviews
- The mean rating you calculated is 2.5
- Is it low because people don't like or because of other reason?
---
### Central Limit Theorem 
Suppose that this is the true distribution: 
.pull-left[
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-13-1.png" width="100%" /&gt;
- But people who post online are more likely to be unhappy
- Suppose you are twice more likely to post if your rating is 1 or 2
- **Sample is not at random** from the population of customers
- Sampling distribution of the mean would look like this:
]

.pull-right[
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-14-1.png" width="100%" /&gt;
It's not centered at the correct value, no matter n !
]

---
### Central Limit Theorem 
Example 2 
What happens if some assumptions are not respected?
- .blue[IID] means one draw does not change likelihood of other draws

**Example**
- Suppose you want to learn what's an average speed of internet in CDMX
- You choose at random the first apartment to measure the speed
- For the rest of the observations, you stay in the same building and measure at neighbors apartments


---
### Central Limit Theorem 
.pull-left[
Suppose that this is the true distribution of speed: 
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-15-1.png" width="100%" /&gt;
- Speed across neighbors in the same building is likely correlated
- Observations are **not independent** 
- Sampling distribution of the mean would look like this:
]

.pull-right[
&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-16-1.png" width="100%" /&gt;
Variance is wider than implied by CLT!
]


---
### Normal Distribution

Consider the event that a customer who opened the DiDi app will call the car.  Suppose X and Y represent the events that a customer calls a car in Cancun (X) and Puerto Vallarta (Y) respectively. 
- X and Y are Bernoulli variables with probabilities 0.4 and 0.6 respectively
- Suppose you have a random (iid) sample  of 100 customers opening the app from Cancun and 80 from Puerto Vallarta. 
- What is the probability that more than 100 people will call the car?

**Reminders**

`$$\text{If } X \sim \mathcal{N}(\mu, \sigma) \text{ and } c \text{ is a constant, then } X + c \sim \mathcal{N}(\mu + c, \sigma)$$`
`$$\text{If } X \sim \mathcal{N}(\mu, \sigma) \text{ and } c \text{ is a constant, then } cX \sim \mathcal{N}(c\mu, |c|\sigma)$$`
`$$\text{If } X \sim \mathcal{N}(\mu_1, \sigma_1) \text{ and } Y \sim \mathcal{N}(\mu_2, \sigma_2), \text{ then } X + Y \sim \mathcal{N}(\mu_1 + \mu_2, \sqrt{\sigma_1^2 + \sigma_2^2})$$`

---

### What if I don't know `\(\sigma\)`

- Suppose that sales in stores are normally distributed with mean 200 and with unknown variance

--
- I want to take a sample of 80 stores and I want to know the probability that the average sales in a sample will be greater than 220

--
`$$P(\frac{\sum_{i=1}^{80} X_i}{80}&gt;220)$$`
Ok, I know that according to central limit theorem `$$\frac{\sum_{i=1}^{80} X_i}{80}\sim N(200, \frac{\sigma}{\sqrt{80}})$$`

--
- But if I don't know `\(\sigma\)` how can I use it?
- We can use the sample standard deviation instead to estimate `\(\sigma\)`

--
- Since it is just an estimate, it adds uncertainty
- But if you have big sample, then you are really good at estimating standard deviation and the error is small
- So the distribution will still converge to normal, but you will need a bit more observations (say 50 rather than 40)


---
## Standard deviation

- Great, sample means have normal distribution in large samples

--

- Can we say something about the standard deviation?

--

- If `\(X_i\)` is normal, then yes! Standard deviation will have **chi-square** distribution 


---

## From Normal to Chi-Square
- We start with the standard random normal distribution N(0, 1).
- The transformation `\(\small X = Z^2\)` gives rise to the Chi-Square distribution with 1 degree of freedom `\(\small  \chi^2(1)\)`.

--
- The expectation of `\(\small \chi^2(1)\)` is `\(\small E[X]=E[Z^2]=Var(Z)+E[Z]^2=Var(Z)=1\)`
- The variance of `\(\small \chi^2(1)\)` is `\(\small var(X)=2\)`

&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-17-1.png" width="100%" /&gt;



---

## Visualizing the Connection
- The shaded areas represent probability that `\(X=Z^2&gt;1\)` 
- Where `\(X \sim \chi^2(1)\)` and `\(Z \sim N(0,1)\)`
- Shaded areas are the same in both graphs

&lt;img src="C_3_slides_a_files/figure-html/unnamed-chunk-18-1.png" width="100%" /&gt;


---

## Chi-Square and the Sum of Random Normals
- More generally, sum of n iid squared standard normal variables is distributed as Chi-Square with n degrees of freedom
- `\(\small \sum_nZ^2\sim \chi^2(n)\)`

--
- The expectation of `\(\small\chi^2(n)\)` is `\(\small E[X(n)]=E[\sum_n Z_i^2]=\sum_n Var(Z_i)=n\)`
- The variance of `\(\small\chi^2(n)\)` is `\(\small var(X)=2n\)`
&lt;center&gt;
&lt;img src=chi_sq.png width="400"&gt;
&lt;/center&gt;

--
- Why the shapes converges to normal with large n? 

--
- Because of CLT - it's sum of random variables


---
### Exercises:

- Review Exercises:
  - PDF 3: 1,2,3,4,6,7(b),9,10,11,12,13,14,15,16

- Homeworks
  - Lista 00.1: 6,7,8,9,10,11,12,13,14,15
  - Lista 00.2: 1,2,3,4,5,6,7,8,9,10,11,12,16,17,18,19,

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
