# Define the rejection region threshold
rejection_threshold <- 1.645
# Create a data frame
data <- data.frame(x = x_values, y = dnorm(x_values))
# Create the plot
p <- ggplot(data, aes(x = x, y = y)) +
geom_line(color = "blue") +
geom_area(data = subset(data, x > rejection_threshold), aes(x = x, y = y), fill = "red", alpha = 0.3) +
geom_vline(xintercept = rejection_threshold, linetype = "dashed", color = "red") +
labs(title = "Rejection Region", x = "X", y = "Density") +
theme_minimal()
# Print the plot
print(p)
data <- data.frame(y = 1)
# Create the plot with a horizontal line at y = 1.645
p <- ggplot(data, aes(y = y)) +
geom_hline(yintercept = 1.645, linetype = "dashed", color = "red") +
labs(title = "Rejection Region", y = "Y") +
theme_minimal()
# Print the plot
print(p)
# Create a data frame with a single row for the horizontal line
data <- data.frame(y = 1)
# Create the plot with a solid horizontal line and a shaded rejection region
p <- ggplot(data, aes(y = y)) +
geom_hline(yintercept = 1, color = "black") +  # Solid horizontal line
geom_rect(aes(xmin = -Inf, xmax = 1.645, ymin = -Inf, ymax = Inf),
fill = "red", alpha = 0.3) +  # Shaded rejection region
labs(title = "Rejection Region", y = NULL, x = NULL) +
theme_minimal() +
theme(axis.text = element_blank(), axis.title = element_blank())  # Hide axis text and labels
# Print the plot
print(p)
xaringan::inf_mr()
20/6
10/3.333
3+1.645
5/3.333
1.5+1.645
-3+1.645
1-0.0885
xaringan::inf_mr()
7*7
2-(1.96*(20/7))
2+(1.96*(20/7))
-2*7
2+(1.96*(1/7))
2-(1.96*(1/7))
3-(1.96*(1/7))
3/7
1/0.428
3-(1.96*(3/7))
3+(1.96*(3/7))
xaringan::inf_mr()
xaringan::inf_mr()
---
Case 2
xaringan::inf_mr()
0.5/2
*6
0.25*6
--
**Example**:
cnorm(1.5)
dnorm(1.5)
?dnorm
qnorm(1.5)
pnorm(1.5)
fnorm(1.5)
pnorm(1.5)
qnorm(0.933)
load("sample_listing.Rda")
library(tidyverse)
ggplot(data=Sample_list, aes(review_score_cleanliness, price))+
geom_point()
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_point()
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_point() +
geom_smooth(method = "loess", fill='darkred', level=0.90)
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_point() +
geom_smooth(method = "line", fill='darkred', level=0.90)
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_point() +
geom_smooth(method = "loess", fill='darkred', level=0.90)
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_point() +
geom_smooth(method = "loess", fill=NA, level=0.90)
library(fixest)
feols(price~review_scores_cleanliness, data=Sample_list)
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_histogram()
ggplot(data=Sample_list, aes(review_scores_cleanliness, price))+
geom_hist()
ggplot(data=Sample_list, aes(review_scores_cleanliness))+
geom_hist()
ggplot(data=Sample_list, aes(review_scores_cleanliness))+
geom_histogram()
ggplot(data=Sample_list, aes(price))+
geom_histogram()
corr(Sample_list$review_scores_cleanliness, Sample_list$price)
cor(Sample_list$review_scores_cleanliness, Sample_list$price)
0.159^2
p=cor(Sample_list$review_scores_cleanliness, Sample_list$price)
p*sqrt(98)
p*sqrt(98)/sqrt(1-0.025)
feols(price~review_scores_cleanliness, data=Sample_list)
p
p=cor(Sample_list$review_scores_cleanliness, Sample_list$price)
p*sqrt(98)/sqrt(1-0.025)
dnorm(p)
pnorm(p)
t=p*sqrt(98)/sqrt(1-0.025)
pnorm(t)
feols(price~review_scores_cleanliness, data=Sample_list)
pnorm(t)
p
t=p*sqrt(198)/sqrt(1-0.025)
t
feols(price~review_scores_cleanliness, data=Sample_list)
pnorm(t)
t
pnorm(2.256)
t
?stud()
stats:pt(2.256, 198)
stats::pt(2.256, 198)
p=cor(Sample_list$review_scores_cleanliness, Sample_list$price)
p
feols(price~review_scores_cleanliness, data=Sample_list)
xaringan::inf_mr()
var(Sample_list$clean)
var(Sample_list$clean==TRUE)
var(Sample_list$price[Sample_list$clean==TRUE])
var(Sample_list$price[Sample_list$clean==FALSE])
925255.5/480681.9
xaringan::inf_mr()
sd(Sample_list$price[Sample_list$clean==TRUE])
sd(Sample_list$price[Sample_list$clean==FALSE])
sd(Sample_list$price[Sample_list$clean==FALSE])
mean(Sample_list$price[Sample_list$clean==TRUE])
mean(Sample_list$price[Sample_list$clean==FALSE])
ggplot(data = Sample_list, aes(x = Clean, y = price)) +
geom_boxplot() +
labs(title = "Boxplot of Price for Clean=True",
x = "Clean",
y = "Price")
ggplot(data = Sample_list, aes(x = clean, y = price)) +
geom_boxplot() +
labs(title = "Boxplot of Price for Clean=True",
x = "Clean",
y = "Price")
ggplot(data = Sample_list, aes(x = clean, y = price)) +
geom_boxplot() +
labs(title = "Boxplot of Price for Clean=True",
x = "Clean",
y = "Price")+
coord_flip()
ggplot(data = Sample_list, aes(x = clean, y = price)) +
geom_boxplot() +
labs(x = "Clean",
y = "Price")+
coord_flip()
xaringan::inf_mr()
df_values <- c(3, 10, 100)  # Different degrees of freedom
x_vals <- seq(0, 5, length.out = 400)
# Create a data frame for ggplot
library(ggplot2)
df1 <- data.frame(x = rep(x_vals, length(df_values)),
y = c(sapply(df_values, function(df) df(x_vals, df1 = df, df2 = 10))),  # Fix df2 at 10
distribution = rep(paste("F-distribution (df1 =", df_values, ", df2 = 10)"), each = length(x_vals)))
df2 <- data.frame(x = rep(x_vals, length(df_values)),
y = c(sapply(df_values, function(df) df(x_vals, df1 = df, df2 = 3))),  # Fix df2 at 10
distribution = rep(paste("F-distribution (df1 =", df_values, ", df2 = 3)"), each = length(x_vals)))
df=rbind(df1,df2)
# Create ggplot object
gg_plot2 <- ggplot(df, aes(x = x, y = y, color = distribution)) +
geom_line() +
labs(x = "x",
y = "Density") +
theme_minimal()
# Convert to plotly object for interactivity
library(plotly)
plotly_object <- ggplotly(gg_plot2,
width = 800,   # Adjust the width according to your preference
height = 400)  # Adjust the height according to your preference
plotly_object
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
remotes::install_github("jhelvy/xaringanBuilder")
install.packages("remotes")
remotes::install_github("jhelvy/xaringanBuilder")
library(xaringanBuilder)
remotes::install_github("jhelvy/xaringanBuilder")
library(renderthis)
build_pdf("C_3_slides_c.html")
remotes::install_github('rstudio/chromote')
to_pdf("C_3_slides_c.html")
1245-869
962^2/100+693^2/100
sqrt(14056.93)
376/118
library(renderthis)
#remotes::install_github('rstudio/chromote')
to_pdf("C_3_slides_c.html")
#remotes::install_github('rstudio/chromote')
to_pdf("C_3_slides_c.html")
xaringan::inf_mr()
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
shiny::runApp('~/T_tests_tradeoff')
runApp('~/T_tests_tradeoff')
library(renderthis)
#remotes::install_github('rstudio/chromote')
to_pdf("C_3_slides_c.html")
# Define the directory containing the ZIP files
zip_dir <- "C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/births/Data_1985_2007"  # Replace with your directory path
# List all ZIP files in the directory
zip_files <- list.files(zip_dir, pattern = "\\.zip$", full.names = TRUE)
# Initialize an empty list to store dataframes
list_of_dataframes <- list()
# Loop through each ZIP file
combined_grouped_df <- NULL
zip_file=zip_files[1]
# Create a temporary directory to extract files
temp_dir <- tempfile()
dir.create(temp_dir)
# Extract the ZIP file
unzip(zip_file, exdir = temp_dir)
# List all files that start with 'NACIM' in the extracted folder
nacim_files <- list.files(temp_dir, pattern = "^NACIM", full.names = TRUE)
nacim_file=nacim_files
df <- read.dbf(nacim_file) %>%
# Select only the necessary columns
select(ENT_RESID, MUN_RESID, SEXO, ANO_NAC, MES_NAC) %>%
# Group by the selected columns and count the number of observations
group_by(ENT_RESID, MUN_RESID, SEXO, ANO_NAC, MES_NAC) %>%
summarise(Count = n(), .groups = 'drop')
df <- read.dbf(nacim_file)
library(tidyverse)
library(stringr)
library(readr)
library(foreign)
df <- read.dbf(nacim_file)
xaringan::inf_mr()
runApp('C:/Users/kzysi/Dropbox/Itam_teaching/Markdowns_2023_2/C4/C4_a/ANOVA')
runApp('C:/Users/kzysi/Dropbox/Itam_teaching/Markdowns_2023_2/C4/C4_a/Linear_regression')
runApp('C:/Users/kzysi/Dropbox/Itam_teaching/Markdowns_2023_2/C4/C4_a/Guess_the_line')
runApp('C:/Users/kzysi/Dropbox/Itam_teaching/Markdowns_2023_2/C4/C4_a/Guess_the_line')
xaringan::inf_mr()
#library(renderthis)
#options("install.lock"=FALSE)
options("install.lock"=FALSE)
install.packages("cli", type="source")
install.packages("cli", type = "source")
#library(renderthis)
#options("install.lock"=FALSE)
options("install.lock"=FALSE)
install.packages("cli", type="source")
install.packages("cli", type = "source")
#library(renderthis)
#options("install.lock"=FALSE)
options("install.lock"=FALSE)
install.packages("cli", type="source")
#library(renderthis)
#options("install.lock"=FALSE)
options("install.lock"=FALSE)
install.packages("cli", type="source")
#library(renderthis)
#options("install.lock"=FALSE)
options("install.lock"=FALSE)
install.packages("cli", type="source", INSTALL_opts = '--no-lock')
remotes::install_github("jhelvy/renderthis", force=TRUE)
#remotes::install_github('rstudio/chromote')
to_pdf("C_3_slides_c.html")
?renderthis
renderthis::to_pdf("C_3_slides_c.html")
load("C:/Users/kzysi/Dropbox/Itam_teaching/Markdowns/Intro_to_r/listings.Rda")
listings$bedrooms_num=as.numeric(listings$bedrooms)
?sample_n
exp_listings <- sample(listings, size = 1000, replace = FALSE)
sample(listings, size = 1000, replace = FALSE)
listings
exp_listings <- listings[sample(nrow(listings), size = 1000, replace = FALSE), ]
sample(nrow(listings), size = 1000, replace = FALSE)
exp_listings$group <- ifelse(runif(nrow(exp_listings)) < 0.5,
"Control", "Treatment")
table(exp_listings$group)
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
table(exp_listings$group)
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
table(exp_listings$group)
##transform to numeric
listings$bed_num=as.numeric(listings$beds)
mean(listings$bed_num, na.rm=TRUE)
mean(exp_listings$bed_num[exp_listings$group=="Treatment", na.rm=TRUE)
mean(exp_listings$bed_num[exp_listings$group=="Treatment"], na.rm=TRUE)
##transform to numeric
listings$bed_num=as.numeric(listings$beds)
mean(exp_listings$bed_num[exp_listings$group=="Treatment"], na.rm=TRUE)
##transform to numeric
exp_listings$bed_num=as.numeric(exp_listings$beds)
mean(exp_listings$bed_num[exp_listings$group=="Treatment"], na.rm=TRUE)
mean(exp_listings$bed_num[exp_listings$group=="Treatment"], na.rm=TRUE)
mean(exp_listings$bed_num[exp_listings$group=="Control"], na.rm=TRUE)
t.test?
?t.test
t.test(exp_listings$bed_num ~ exp_listings$group)
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
mean(exp_listings$bed_num[exp_listings$group=="Treatment"], na.rm=TRUE)
mean(exp_listings$bed_num[exp_listings$group=="Control"], na.rm=TRUE)
t.test(exp_listings$bed_num ~ exp_listings$group)
B=exp_listings$bed_num[exp_listings$group=="Control"]
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
##transform to numeric
exp_listings$bed_num=as.numeric(exp_listings$bedrooms)
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
listings$bed_num=as.numeric(listings$beds) ##transform number of beds to numeric and
listings=listings[!is.na(listings$bed_num)] ### keep only those with a valid number of beds
exp_listings <- listings[sample(nrow(listings), size = 1000, replace = FALSE), ]
listings$bed_num=as.numeric(listings$beds) ##transform number of beds to numeric and
listings=listings[!is.na(listings$bed_num),] ### keep only those with a valid number of beds
exp_listings <- listings[sample(nrow(listings), size = 1000, replace = FALSE), ]
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
table(exp_listings$group)
##transform to numeric
exp_listings$bed_num=as.numeric(exp_listings$beds)
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
##transform to numeric
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
##transform to numeric
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
listings$bed_num=as.numeric(listings$beds) ##transform number of beds to numeric and
listings=listings[!is.na(listings$bed_num),] ### keep only those with a valid number of beds
exp_listings <- listings[sample(nrow(listings), size = 2000, replace = FALSE), ]
exp_listings$group <- ifelse(rbinom(nrow(exp_listings), 1, 0.5) == 1, "Treatment", "Control") #I draw a bernouill variable (binomial with n=1) for everyone. If you got 1, you are treated, if 0 you got control
table(exp_listings$group)
##transform to numeric
A=exp_listings$bed_num[exp_listings$group=="Treatment"]
B=exp_listings$bed_num[exp_listings$group=="Control"]
(mean(A)-mean(B))/sqrt(var(A)/length(A)+var(B)/length(B)) #t statistic for difference in means
#how would you check if the distribution across neighborhoods is equal?
table(exp_listings$neighbourhood_cleansed,exp_listings$group) #contingency table
library(rsinaica)
m=stations_sinaica()
m=stations_sinaica
View(m)
View(m)
set.seed(123)
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = round(rnorm(50, mean = 210, sd = 40))
)
tweets$likes
set.seed(123)
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = round(rnorm(50, mean = 210, sd = 40))
)
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = round(rnorm(50, mean = 190, sd = 40))
)
tweets[tweets$likes>0,
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = rnbinom(50, size = 20, mu = 210)  # 50 tweets
)
hist(tweets$likes)
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = rnbinom(50, size = 20, mu = 180)  # 50 tweets
)
M=mean(tweets$likes)
S=sd(tweets$likes)
SE=50
T=(M-200)/SE
Test_stat=(M-200)/SE
SE=S/sqrt(50)
(M-200)/SE
# Generate synthetic tweet likes around mean ~210 with some variation
tweets <- data.frame(
likes = rnbinom(50, size = 20, mu = 190)  # 50 tweets
)
Mean=___ # mean of tweets
S=___ # standard deviation of tweets
SE=_____ #standard error of the estimator
Test_stat=(M-200)/SE
Mean=___ # mean of tweets
M=mean(tweets$likes)
S=sd(tweets$likes)
SE=s/sqrt
SE=s/sqrt(50)
SE=S/sqrt(50)
Test_stat=(M-200)/SE
Test_stat
We collect a random sample of 100 tweets from the campaign and measure their number of likes. Suppose 5% significance level.
We collect a random sample of 80 tweets from the campaign and measure their number of likes. Suppose 5% significance level.
qt(0.95,49) #quantile from student t distribution with 49 degree of freedom
qnorm(0.95) #quantile from normal distribution
qt(0.98,49) #quantile from student t distribution with 49 degree of freedom
qnorm(0.98) #quantile from normal distribution
Test_stat
qt(0.99,49) #quantile from student t distribution with 49 degree of freedom
qnorm(0.99) #quantile from normal distribution
qt(0.995,49)
qt(0.994,49)
n=100
Diff=8
SD=7
n=100
Diff=8
SD=7
D=869
n=100
Diff=8
SD=7
n=100
Diff=8
SD=7
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
D=869
SDC=962
SDD=693
nC=100
nD=100
D=869
SDC=962
SDD=693
nC=100
n=100
Diff=8
SD=7
alpha=0.01
n=100
Diff=8
SD=7
alpha=0.01
D=869
D=869
