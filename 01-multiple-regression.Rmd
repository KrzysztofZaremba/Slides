
```{r include=FALSE}
library(car)
simpleAnova <- function(object, ...) {

  # Compute anova table
  tab <- anova(object, ...)

  # Obtain number of predictors
  p <- nrow(tab) - 1

  # Add predictors row
  predictorsRow <- colSums(tab[1:p, 1:2])
  predictorsRow <- c(predictorsRow, predictorsRow[2] / predictorsRow[1])

  # F-quantities
  Fval <- predictorsRow[3] / tab[p + 1, 3]
  pval <- pf(Fval, df1 = p, df2 = tab$Df[p + 1], lower.tail = FALSE)
  predictorsRow <- c(predictorsRow, Fval, pval)

  # Simplified table
  tab <- rbind(predictorsRow, tab[p + 1, ])
  row.names(tab)[1] <- "Predictors"
  return(tab)

}



```


# Multiple Linear Regression: Model Evaluation and Hypothesis Testing

## Introduction

In multiple linear regression, we model the relationship between a dependent variable \( y \) and multiple independent variables \( x_1, x_2, \dots, x_k \). Our goal is not only to predict \( y \) but also to understand how each predictor influences it.

In this chapter, we will carefully explore how to evaluate the significance of the overall model and how to test specific hypotheses about individual or groups of coefficients. We'll use the `marketing` dataset from the `datarium` package as an illustrative example. This dataset includes information on the budget allocated to advertising through YouTube, Facebook, and newspaper platforms, along with the corresponding sales generated.

```{r}
library(datarium)
data(marketing)
head(marketing)
```

Businesses frequently invest in advertising across various media channels, and it’s essential to understand which channels effectively drive sales. This understanding helps optimize advertising budgets and maximize return on investment (ROI).



## ANOVA and F-Test for Overall Significance

### Why Do We Need the F-Test?

The F-test in multiple regression helps us determine whether our model provides a significantly better fit than a model with no predictors.

Formally, the null hypothesis is:

\[
H_0: \beta_1 = \beta_2 = \dots = \beta_k = 0
\]

In words, none of the independent variables have an effect on \( y \).

Under \( H_0 \), the model reduces to:

\[
y = \beta_0 + u
\]

which is simply a horizontal line at the mean of \( y \). In this case, the regression is useless for explaining \( y \).

The alternative hypothesis is:

\[
H_A: \text{At least one } \beta_j \neq 0
\]

Rejecting \( H_0 \) suggests that at least one predictor significantly explains variation in \( y \).



### Intuition Behind the F-Test

If our model is useful, it should explain a large proportion of the total variability in \( y \).

To evaluate this, we decompose the total variability into:

- **Explained variation** (SSR): how much variability the regression explains
- **Unexplained variation** (SSE): how much variability remains unexplained (residuals)

Thus, we have:

\[
TSS = SSR + SSE
\]

where:

- **TSS**: Total Sum of Squares (total variation around the mean)
- **SSR**: Regression Sum of Squares (variation explained by the model)
- **SSE**: Error Sum of Squares (residual variation)



### Degrees of Freedom

The decomposition and degrees of freedom (df) are summarized in the table:

| Component | Formula | Interpretation | Degrees of Freedom |
|--||--|--|
| TSS | \( \sum (y_i - \bar{y})^2 \) | Total variation around the mean | \( n - 1 \) |
| SSR | \( \sum (\hat{y}_i - \bar{y})^2 \) | Explained variation | \( k \) |
| SSE | \( \sum (y_i - \hat{y}_i)^2 \) | Unexplained (residual) variation | \( n - k - 1 \) |

Note:
- The degrees of freedom add up: \( (k) + (n - k - 1) = (n - 1) \).
- SSR + SSE = TSS.



### Understanding the F-Statistic

The F-statistic compares the mean explained variation to the mean unexplained variation:

\[
F = \frac{SSR / k}{SSE / (n - k - 1)}
\]

If the model is useless (all \( \beta_j = 0 \)), then SSR will be small, and the F-statistic will be close to 1.

If the model is useful (some \( \beta_j \neq 0 \)), SSR will be large compared to SSE, and the F-statistic will be significantly greater than 1.



### Intuitive Explanation of the F-Test

- If \( H_0 \) is true, \( F \) should be small.
- A large F-statistic provides evidence to reject \( H_0 \).

The p-value associated with the F-statistic is:

- \( p = P(F_{k, n-k-1} > F_{\text{observed}}) \)

where \( F_{k, n-k-1} \) denotes the F-distribution with \( k \) and \( n-k-1 \) degrees of freedom.

**Important**: 
- This is a **one-sided test**.
- We only reject \( H_0 \) if the F-statistic is sufficiently large (no need to double the p-value).

## Alternative Perspective: Extra Sum of Squares Approach

Another way to understand the F-test is to think in terms of comparing two models:

- **Restricted model** (under \( H_0 \)): only includes the intercept.
\[
H_0: y = \beta_0 + u
\]
- **Unrestricted model** (under \( H_A \)): includes all predictors.
\[
H_A: y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k + u
\]

If \( H_A \) is true, the unrestricted model should explain significantly more variation than the restricted model.

Thus, the F-statistic can also be written as:

\[
F = \frac{
\left( \text{SSE}_{\text{restricted}} - \text{SSE}_{\text{unrestricted}} \right) / (k - k_0)
}{
\text{SSE}_{\text{unrestricted}} / (n - k)
}
\]

where:

- \( \text{SSE}_{\text{restricted}} \): residual sum of squares from the restricted model (intercept only)
- \( \text{SSE}_{\text{unrestricted}} \): residual sum of squares from the full model
- \( k_0 \): number of predictors in the restricted model (typically 0)

Because the restricted model explains nothing (only the mean), \( SSR_{H_0} = 0 \), and the difference simplifies to \( SSR \) of the unrestricted model.

Thus, this "extra sum of squares" formulation is mathematically equivalent to the earlier F-formula based on explained and unexplained variation.


## Example with Marketing Data

Let's apply our detailed understanding of multiple regression analysis using the `marketing` dataset from the `datarium` package. Specifically, we want to examine how advertising expenditures on YouTube, Facebook, and newspapers influence product sales.

We will estimate the following regression equation:

\[
sales_i = \beta_0 + \beta_1 \, youtube_i + \beta_2 \, facebook_i + \beta_3 \, newspaper_i + u_i
\]

Each coefficient \( \beta \) measures the change in sales associated with each additional dollar invested in the respective advertising platform, holding the others constant.



### Step-by-Step Regression in R

Here's how we perform this regression analysis using R:

```{r}
# Fit the multiple regression model
model <- lm(sales ~ youtube + facebook + newspaper, data = marketing)

# Display detailed summary
summary(model)
```



### Interpreting the Model Output

Let's carefully interpret the output:

*Coefficients:**

1. **Intercept:** 3.5267 — the expected sales when there is no spending on any platform.
2. **YouTube coefficient:** 0.0458 — each additional dollar spent on YouTube advertising increases sales by approximately 0.0458 units, holding Facebook and newspaper spending constant.
3. **Facebook coefficient:** 0.1885 — each additional dollar spent on Facebook advertising increases sales by about 0.1885 units, ceteris paribus.
4. **Newspaper coefficient:** -0.0010 — spending on newspaper advertising shows a very small, statistically insignificant, negative effect on sales.

**Statistical significance:**

1. YouTube and Facebook coefficients are highly statistically significant (p-values < 0.001), indicating strong evidence that these platforms positively influence sales.
2. Newspaper advertising is not statistically significant (p-value ≈ 0.86), suggesting no effect.


### ANOVA Table for Detailed Insights

The Analysis of Variance (ANOVA) table summarizes how much of the variability in sales is explained by the model.

The `anova()` function in R provides a decomposition of sum of squares for each predictor separately. To get the total explained variation (SSR), we add the sum of squares for YouTube, Facebook, and Newspaper.

```{r}
anova(model)
```

**Note:**  
- R reports the **Sum of Squares** for each predictor separately (e.g., YouTube, Facebook, Newspaper).  
- **Adding them together** gives the total explained sum of squares (SSR).

To obtain a simplified classic ANOVA table (model vs residuals), we can use a custom function like `simpleAnova(model)` (assuming it's pre-written).

```{r}
simpleAnova(model)
```



### Understanding the ANOVA Output

From the ANOVA table:

- **Sum of Squares Regression (SSR):** Add contributions from YouTube, Facebook, and Newspaper.  
  SSR ≈ 6,998.9
- **Sum of Squares Error (SSE):** Residuals ≈ 801.8
- **Degrees of Freedom:**
  - Regression df = 3 (number of predictors)
  - Residual df = 196 (total observations - predictors - 1)
- **Mean Squares:**
  - MSR = SSR / df_regression
  - MSE = SSE / df_residuals
- **F-statistic:**
  - Reported as 570.3
- **P-value:**
  - Less than 2.2e-16 (very strong evidence against \( H_0 \)).



### Clearly Formulated Hypotheses

Let’s explicitly write the ANOVA F-test hypotheses:

\[
H_0: \beta_{\text{youtube}} = \beta_{\text{facebook}} = \beta_{\text{newspaper}} = 0
\]

\[
H_A: \text{At least one } \beta_j \neq 0
\]

Decision rule:
- **Reject \( H_0 \)** if the F-statistic is larger than the critical F-value (or if the p-value is smaller than 0.05).
- **Rejecting \( H_0 \)** confirms that advertising expenditures (at least on one platform) significantly affect sales.



### Distribution of the F-Statistic Under the Null

Given that we have 200 observations, under \( H_0 \) (no advertising effect):

- Numerator degrees of freedom = 3 (predictors)
- Denominator degrees of freedom = \( n - k - 1 = 200 - 3 - 1 = 196 \)

At a 5% significance level, the critical value of the F-distribution \( F(3, 196) \) is approximately 2.65.



### Calculating the F-Statistic Manually

Recall:

\[
F = \frac{SSR/k}{SSE/(n-k-1)}
\]

Substituting the numbers:

\[
F = \frac{6998.9/3}{801.8/196} = 570.3
\]

However, because in R’s calculation each contribution to SSR is added separately, and model fitting automatically adjusts for estimation, the reported F-statistic (570.3) corresponds correctly to the model summary and internal variance estimates.

(You can double-check by looking at Mean Squares: MSR / MSE.)



### Conclusion

- The calculated F-statistic (570.3) is far larger than the critical value (2.65).
- The p-value is extremely small (0).
- Thus, we **strongly reject the null hypothesis**.
- Conclusion: Advertising spending on at least one platform significantly influences product sales.



### Relationships between coefficients 
Sometimes we are interested in testing the relationships between coefficients in the model. That allows us to compare effects of different variables or look at their sums. 

Consider a model: 
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k + u
\]


### Difference between coefficients

- We are interested in testing whether the **difference between the impact of** \( x_1 \) **and** \( x_2 \) **is equal to a constant** \( c \).

**Hypotheses:**
- \( H_0: \beta_1 - \beta_2 = c \)
- \( H_A: \beta_1 - \beta_2 \neq c \)



- A **special case** is when \( c = 0 \), meaning we are testing whether the coefficients are equal:
  
\[
H_0: \beta_1 - \beta=0
\]
Which is the same as:
\[
H_0: \beta_1 = \beta_2
\]



#### Test Statistic and Its Distribution Under the Null

The test statistic is:

\[
T_{\text{test}} = \frac{ \hat{\beta}_1 - \hat{\beta}_2 - c }{ SE(\hat{\beta}_1 - \hat{\beta}_2) }
\]

where

\[
SE(\hat{\beta}_1 - \hat{\beta}_2) = \sqrt{ \text{Var}(\hat{\beta}_1) + \text{Var}(\hat{\beta}_2) - 2\text{Cov}(\hat{\beta}_1, \hat{\beta}_2) }
\]

Under \( H_0 \), the test statistic follows a t-distribution:

\[
T_{\text{test}} \sim t_{n-k-1}
\]

where:
- \( n \) is the number of observations
- \( k \) is the number of predictors (excluding intercept)

We calculate the p-value as:

\[
\text{p-value} = 2P(t_{n-k-1} > |T_{\text{test}}|)
\]




### Testing Inequalities Between Coefficients

Similarly, we can test whether **one coefficient is greater than** another by a given amount.

**Hypotheses:**
- \( H_0: \beta_1 - \beta_2 = c \)
- \( H_A: \beta_1 - \beta_2 > c \)



- Special case when \( c = 0 \): testing whether \( \beta_1 > \beta_2 \).



#### Test Statistic and p-Value

The test statistic remains:

\[
T_{\text{test}} = \frac{ \hat{\beta}_1 - \hat{\beta}_2 - c }{ SE(\hat{\beta}_1 - \hat{\beta}_2) }
\]

and under \( H_0 \):

\[
T_{\text{test}} \sim t_{n-k-1}
\]

The p-value depends on the direction of the alternative hypothesis:

- For \( H_A: \beta_1 - \beta_2 > c \):
  
\[
\text{p-value} = P(t_{n-k-1} > T_{\text{test}})
\]

- For \( H_A: \beta_1 - \beta_2 < c \):

\[
\text{p-value} = P(t_{n-k-1} < T_{\text{test}})
\]



## Testing the sum of the coefficients: 


- We are interested in testing whether the **sum of the impacts of** \( x_1 \) **and** \( x_2 \) **is equal to a constant** \( c \).

**Hypotheses:**
- \( H_0: \beta_1 + \beta_2 = c \)
- \( H_A: \beta_1 + \beta_2 \neq c \)



- Helps to answer
  - Is combined effect bigger than some number?
  - Does increasing both at the same time has positive or negative effect (if coefficients have opposite signs)?
  
\[
H_0: \beta_1 + \beta=0
\]

vs 

\[
H_A: \beta_1 + \beta \neq 0
\]

or for one sided tests:

\[
H_A: \beta_1 + \beta >0
\]

or 

\[
H_A: \beta_1 + \beta <0
\]

#### Test Statistic and Its Distribution Under the Null

The test statistic is:

\[
T_{\text{test}} = \frac{ \hat{\beta}_1 + \hat{\beta}_2 - c }{ SE(\hat{\beta}_1 + \hat{\beta}_2) }
\]

where (sings on covariance changes):

\[
SE(\hat{\beta}_1 + \hat{\beta}_2) = \sqrt{ \text{Var}(\hat{\beta}_1) + \text{Var}(\hat{\beta}_2) + 2\text{Cov}(\hat{\beta}_1, \hat{\beta}_2) }
\]

Under \( H_0 \), the test statistic follows a t-distribution:

\[
T_{\text{test}} \sim t_{n-k-1}
\]

where:
- \( n \) is the number of observations
- \( k \) is the number of predictors (excluding intercept)

We calculate the p-value  for two sided test as:

\[
\text{p-value} = 2P(t_{n-k-1} > |T_{\text{test}}|)
\]

And for one sided test we don't mulitply by 2.



## Application Example: Testing Equality of Facebook and Newspaper Effects

Suppose we want to test whether the effect of Facebook advertising is **equal to** the effect of Newspaper advertising.

As a reminder:

| Coefficient  | Estimate | Std. Error |
|--|-||
| (Intercept)  | 3.526667 | 0.374290    |
| YouTube      | 0.045765 | 0.001395    |
| Facebook     | 0.188530 | 0.008611    |
| Newspaper    | -0.001037 | 0.005871   |

Formally:

\[
H_0: \beta_{\text{facebook}} = \beta_{\text{newspaper}}
\]

This is equivalent to testing:

\[
H_0: \beta_{\text{facebook}} - \beta_{\text{newspaper}} = 0
\]

against the alternative:

\[
H_A: \beta_{\text{facebook}} - \beta_{\text{newspaper}} \neq 0
\]



### Manual Calculation: Step-by-Step

We can calculate the test manually. Extract the variance-covariance matrix of estimated coefficients:

```{r}
vcov(model)
```


- \( \text{Var}(\hat{\beta}_{\text{facebook}}) = 7.415335 \times 10^{-5} \)
- \( \text{Var}(\hat{\beta}_{\text{newspaper}}) = 3.446875 \times 10^{-5} \)
- \( \text{Cov}(\hat{\beta}_{\text{facebook}}, \hat{\beta}_{\text{newspaper}}) = -1.780062 \times 10^{-5} \)

_Remember_: In the variance-covariance matrix, the first row/column corresponds to the intercept!



#### Step 1: Calculate the Standard Error

We use the formula:

\[
SE(\hat{\beta}_{\text{facebook}} - \hat{\beta}_{\text{newspaper}})
= \sqrt{ \text{Var}(\hat{\beta}_{\text{facebook}}) + \text{Var}(\hat{\beta}_{\text{newspaper}}) - 2\text{Cov}(\hat{\beta}_{\text{facebook}}, \hat{\beta}_{\text{newspaper}}) }
\]

Substituting values:

\[
SE = \sqrt{ (7.415335 \times 10^{-5}) + (3.446875 \times 10^{-5}) - 2(-1.780062 \times 10^{-5}) }
\]
\[
SE = \sqrt{ (7.415335 + 3.446875 - 2 \times -1.780062) \times 10^{-5} }
\]
\[
SE = \sqrt{ 0.0001442233 }
\]
\[
SE \approx 0.0120093
\]

Thus:

\[
SE(\hat{\beta}_{\text{facebook}} - \hat{\beta}_{\text{newspaper}}) \approx 0.0120093
\]



#### Step 2: Calculate the Test Statistic

The formula for the test statistic is:

\[
T_{\text{test}} = \frac{ \hat{\beta}_{\text{facebook}} - \hat{\beta}_{\text{newspaper}} - 0 }{ SE(\hat{\beta}_{\text{facebook}} - \hat{\beta}_{\text{newspaper}}) }
\]

Substituting in the estimates:

\[
T_{\text{test}} = \frac{ 0.188530 - (-0.001037) }{ 0.0120093 }
\]
\[
T_{\text{test}} = \frac{ 0.189567 }{ 0.0120093 }
\]
\[
T_{\text{test}} \approx 15.78
\]



#### Step 3: Find the p-value

Under \( H_0 \), the test statistic follows a \( t \)-distribution with \( n - k - 1 \) degrees of freedom.

In this case:
- \( n = 200 \) observations
- \( k = 3 \) predictors (YouTube, Facebook, Newspaper)

Thus:

\[
\text{Degrees of Freedom} = 200 - 3 - 1 = 196
\]

The p-value for a two-sided test is:

\[
\text{p-value} = 2P(t_{196} > 15.78)
\]

Given that 15.78 is extremely large, the p-value is effectively close to zero (\( < 0.0001 \)).

Thus, we **strongly reject** the null hypothesis that the effect of Facebook equals the effect of Newspaper.



### Additional example: Comparing 4 Dollars in YouTube to 1 Dollar in Facebook

We want to test whether **spending 4 dollars on YouTube has the same effect as spending 1 dollar on Facebook**.

In other words, we want to test:

\[
H_0: 4\beta_{\text{youtube}} = \beta_{\text{facebook}}
\]

This can be rearranged into the standard form:

\[
H_0: 4\beta_{\text{youtube}} - \beta_{\text{facebook}} = 0
\]

**Alternative Hypothesis:**

\[
H_A: 4\beta_{\text{youtube}} - \beta_{\text{facebook}} \neq 0
\]



#### Step 1: Calculate the Estimate of the Linear Combination

From the regression output:

- \( \hat{\beta}_{\text{youtube}} = 0.045765 \)
- \( \hat{\beta}_{\text{facebook}} = 0.188530 \)

Thus:

\[
4\hat{\beta}_{\text{youtube}} - \hat{\beta}_{\text{facebook}} = 4(0.045765) - 0.188530
\]
\[
= 0.18306 - 0.188530 = -0.00547
\]



#### Step 2: Calculate the Standard Error

The variance of the linear combination \( 4\hat{\beta}_{\text{youtube}} - \hat{\beta}_{\text{facebook}} \) is:

\[
\text{Var}(4\hat{\beta}_{\text{youtube}} - \hat{\beta}_{\text{facebook}}) = 4^2 \times \text{Var}(\hat{\beta}_{\text{youtube}}) + (-1)^2 \times \text{Var}(\hat{\beta}_{\text{facebook}}) + 2 \times 4 \times (-1) \times \text{Cov}(\hat{\beta}_{\text{youtube}}, \hat{\beta}_{\text{facebook}})
\]

Substituting the given values from above variance covariance matrix:

\[
= 16 \times 1.945737\times 10^{-6} + 1 \times 7.415335\times 10^{-5} + 2 \times 4 \times (-1) \times (-4.470395\times 10^{-7})
\]
\[
= 16 \times 0.000001945737 + 0.00007415335 + 2 \times 4 \times 0.0000004470395
\]
\[
= 0.000031131792 + 0.00007415335 + 0.000003576316
\]
\[
= 0.00010886146
\]

Thus:

\[
SE = \sqrt{0.00010886146} \approx 0.01043
\]



#### Step 3: Calculate the Test Statistic

\[
T_{\text{test}} = \frac{-0.00547 - 0}{0.01043} \approx -0.524
\]



#### Step 4: Find the p-value

- Degrees of freedom = \( 200 - 3 - 1 = 196 \)
- The p-value for a two-sided test is:

\[
\text{p-value} = 2P(t_{196} > 0.524)=0.7
\]

Since \( T_{\text{test}} \) is small in absolute value, the p-value will be large (>0.5).

**Conclusion:**  
We **fail to reject** \( H_0 \). There is no evidence that the effect of 4 dollars in YouTube is different from 1 dollar in Facebook.




### Example 2: Testing if the Combined Effect of YouTube and Facebook Exceeds 0.22

Now, we want to test whether **the sum of the effects of 1 dollar in YouTube and 1 dollar in Facebook** is **greater than** 0.22.

Formally:

\[
H_0: \beta_{\text{youtube}} + \beta_{\text{facebook}} = 0.22
\]
\[
H_A: \beta_{\text{youtube}} + \beta_{\text{facebook}} > 0.22
\]



#### Step 1: Calculate the Estimate of the Linear Combination

\[
\hat{\beta}_{\text{youtube}} + \hat{\beta}_{\text{facebook}} = 0.045765 + 0.188530 = 0.234295
\]



#### Step 2: Calculate the Standard Error

The variance of the linear combination \( \hat{\beta}_{\text{youtube}} + \hat{\beta}_{\text{facebook}} \) is:

\[
\text{Var}(\hat{\beta}_{\text{youtube}} + \hat{\beta}_{\text{facebook}}) = \text{Var}(\hat{\beta}_{\text{youtube}}) + \text{Var}(\hat{\beta}_{\text{facebook}}) + 2\text{Cov}(\hat{\beta}_{\text{youtube}}, \hat{\beta}_{\text{facebook}})
\]

Substituting values:

\[
= 1.945737\times 10^{-6} + 7.415335\times 10^{-5} + 2 \times (-4.470395\times 10^{-7})
\]
\[
= 0.000001945737 + 0.00007415335 - 0.000000894079
\]
\[
= 0.000075205008
\]

Thus:

\[
SE = \sqrt{0.000075205008} \approx 0.008673
\]



#### Step 3: Calculate the Test Statistic

\[
T_{\text{test}} = \frac{0.234295 - 0.22}{0.008673} = \frac{0.014295}{0.008673} \approx 1.648
\]



#### Step 4: Find the p-value

Since this is a **one-sided test** (greater than), we compute:

\[
\text{p-value} = P(t_{196} > 1.648)=0.0504
\]

Consulting the t-distribution, the p-value is approximately 0.05.

**Conclusion:**
- The p-value is slightly above 0.05.
- Thus, there is no evidence to reject \( H_0 \) at the 5% level, but you could reject at 10\%
- **Interpretation**: There is weak evidence that the combined effect exceeds 0.22. Or you could say there is no strong evidence to reject. 

