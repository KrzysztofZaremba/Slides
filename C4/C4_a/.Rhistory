Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
Inf_mort
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Inf_mort, weights=~Count, split=~tertile)
Inf_mort=merge(Inf_mort, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Inf_mort, weights=~Count, split=~tertile)
etable(reg1,reg2,reg3, tex=TRUE)
reg3
etable(reg1,reg2,reg3, tex=TRUE)
load("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/Direct_regressions_data.Rda")
MR_E=Direct_data[[1]]
Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
#merge each data set with Inf_mort_mun to get the tertile information
MR_E=merge(MR_E, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=MR_E, weights=~W, split=~tertile)
Fertility=merge(Fertility, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg2=feols(bper1000w~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Fertility, weights=~Female_pop, split=~tertile)
Inf_mort=merge(Inf_mort, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Inf_mort, weights=~Count, split=~tertile)
etable(reg1,reg2,reg3, tex=TRUE)
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=MR_E, weights=~W)
reg1
#merge each data set with Inf_mort_mun to get the tertile information
MR_E=merge(MR_E, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=MR_E, weights=~W)
load("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/Direct_regressions_data.Rda")
MR_E=Direct_data[[1]]
Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
#merge each data set with Inf_mort_mun to get the tertile information
MR_E=merge(MR_E, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=MR_E, weights=~W)
Fertility=merge(Fertility, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg2=feols(bper1000w~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=Fertility, weights=~Female_pop)
Inf_mort=merge(Inf_mort, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+Date^tertile, data=Inf_mort, weights=~Count)
etable(reg1,reg2,reg3, tex=TRUE)
load("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/Direct_regressions_data.Rda")
MR_E=Direct_data[[1]]
Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
#merge each data set with Inf_mort_mun to get the tertile information
MR_E=merge(MR_E, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=MR_E, weights=~W)
Fertility=merge(Fertility, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg2=feols(bper1000w~ share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=Fertility, weights=~Female_pop)
Inf_mort=merge(Inf_mort, Inf_mort_mun[,c("MUN","tertile")], by="MUN")
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+tertile^Date, data=Inf_mort, weights=~Count)
etable(reg1,reg2,reg3, tex=TRUE)
library(readxl)
Localized_Lead_Sources <- read_excel("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/RA_Salvador/Week 6/Week 6/Alternative Lead Sources/Localized Lead Sources.xlsx")
View(Localized_Lead_Sources)
library(tidyverse)
library(fixest)
load("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/Direct_regressions_data.Rda")
MR_E=Direct_data[[1]]
Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=MR_E[!MR_E$MUN%in%Localized_Lead_Sources$`Municipality code`], weights=~W)
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=MR_E[!MR_E$MUN%in%Localized_Lead_Sources$`Municipality code`,], weights=~W)
reg2=feols(bper1000w~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Fertility[!Fertility$MUN%in%Localized_Lead_Sources$`Municipality code`,], weights=~Female_pop)
load("C:/Users/kzysi/Dropbox/Air pollution intergenerational effect/data/Direct_regressions_data.Rda")
MR_E=Direct_data[[1]]
Fertility=Direct_data[[2]]
Inf_mort=Direct_data[[3]]
reg1=feols(Mortality_per_1000_births~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=MR_E[!MR_E$MUN%in%Localized_Lead_Sources$`Municipality code`,], weights=~W)
reg2=feols(bper1000w~ share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Fertility[!Fertility$MUN%in%Localized_Lead_Sources$`Municipality code`,], weights=~Female_pop)
reg3=feols(Mortality1000~share_within_5km*full_pregnancy_exposure|
MUN+Date, data=Inf_mort[!Inf_mort$MUN%in%Localized_Lead_Sources$`Municipality code`,], weights=~Count)
etable(reg1,reg2,reg3, tex=TRUE)
etable(reg1,reg2,reg3, tex=TRUE)
shiny::runApp('ANOVA')
library(learnr)
library(shiny)
library(tidyverse)
if (!requireNamespace("plotly", quietly = TRUE)) {
install.packages("plotly")
}
if (!requireNamespace("tseries", quietly = TRUE)) {
install.packages("tseries")
}
library(plotly)
if (!requireNamespace("probstats4econ", quietly = TRUE)) {
install.packages("probstats4econ")
}
library(probstats4econ)
# Fixed data generation
set.seed(123) # For reproducibility
x <- seq(-10, 10, by = 1)
e <- rnorm(length(x), mean = 0, sd = 5)
y_actual <- 4 + 1.65 * x + e
data <- data.frame(x, y_actual)
sexratios <- read.table(text="
21163 2000-2004 2020 985 901 0.4777306 1886
08063 2000-2004 2020 190 175 0.4794521 365
20544 2000-2004 2020 23 22 0.4888889 45
14080 2000-2004 2020 167 189 0.5308989 356
19039 2000-2004 2020 45696 46977 0.5069114 92673
14017 2000-2004 2020 494 520 0.5128205 1014
28023 2000-2004 2020 137 142 0.5089606 279
20462 2000-2004 2020 173 203 0.5398936 376
20359 2000-2004 2020 16 19 0.5428571 35
07023 2000-2004 2020 5775 4946 0.4613376 10721
24004 2000-2004 2020 176 146 0.4534161 322
28026 2000-2004 2020 127 165 0.5650685 292
07099 2000-2004 2020 3796 3549 0.4831858 7345
21029 2000-2004 2020 184 172 0.4831461 356
11025 2000-2004 2020 4050 4158 0.5065789 8208
21083 2000-2004 2020 1160 1090 0.4844444 2250
07018 2000-2004 2020 478 468 0.4947146 946
26016 2000-2004 2020 201 197 0.4949749 398
16088 2000-2004 2020 5310 5306 0.4998116 10616
20135 2000-2004 2020 372 333 0.4723404 705
14035 2000-2004 2020 2200 2287 0.5096947 4487
05009 2000-2004 2020 2690 2698 0.5007424 5388
10005 2000-2004 2020 30545 30975 0.5034948 61520
17023 2000-2004 2020 338 388 0.5344353 726
20375 2000-2004 2020 614 587 0.4887594 1201
11001 2000-2004 2020 4245 4254 0.5005295 8499
26020 2000-2004 2020 198 224 0.5308057 422
29037 2000-2004 2020 453 443 0.4944196 896
31024 2000-2004 2020 153 151 0.4967105 304
32009 2000-2004 2020 379 395 0.5103359 774
12079 2000-2004 2020 1078 1050 0.4934211 2128
20041 2000-2004 2020 1257 1117 0.4705139 2374
30020 2000-2004 2020 697 640 0.4786836 1337
13083 2000-2004 2020 2435 2501 0.5066856 4936
20107 2000-2004 2020 1223 1164 0.4876414 2387
31064 2000-2004 2020 67 50 0.4273504 117
30207 2000-2004 2020 1825 1838 0.5017745 3663
12061 2000-2004 2020 1902 2019 0.5149197 3921
11019 2000-2004 2020 2155 2057 0.4883666 4212
31079 2000-2004 2020 2158 2107 0.4940211 4265
16064 2000-2004 2020 1218 1195 0.4952341 2413
10003 2000-2004 2020 165 182 0.5244957 347
21124 2000-2004 2020 716 779 0.5210702 1495
20492 2000-2004 2020 78 92 0.5411765 170
07076 2000-2004 2020 1523 1519 0.4993425 3042
20103 2000-2004 2020 262 240 0.4780876 502
17003 2000-2004 2020 1678 1644 0.4948826 3322
31057 2000-2004 2020 345 341 0.4970845 686
20222 2000-2004 2020 39 58 0.5979381 97
20006 2000-2004 2020 913 837 0.4782857 1750
20551 2000-2004 2020 1235 1171 0.4866999 2406
30111 2000-2004 2020 676 634 0.4839695 1310
31093 2000-2004 2020 749 795 0.5148964 1544
12002 2000-2004 2020 1296 1155 0.4712362 2451
05011 2000-2004 2020 485 465 0.4894737 950
20303 2000-2004 2020 25 34 0.5762712 59
20076 2000-2004 2020 169 152 0.4735202 321
09005 2000-2004 2020 42664 44622 0.5112160 87286
20196 2000-2004 2020 6 14 0.7000000 20
27001 2000-2004 2020 2491 2506 0.5015009 4997
14067 2000-2004 2020 12524 12616 0.5018298 25140
20085 2000-2004 2020 1367 1376 0.5016405 2743
16006 2000-2004 2020 5535 5524 0.4995027 11059
14051 2000-2004 2020 1298 1254 0.4913793 2552
20240 2000-2004 2020 149 137 0.4790210 286
21192 2000-2004 2020 240 238 0.4979079 478
21032 2000-2004 2020 32 50 0.6097561 82
31104 2000-2004 2020 801 854 0.5160121 1655
14021 2000-2004 2020 796 802 0.5018773 1598
31086 2000-2004 2020 87 83 0.4882353 170
32017 2000-2004 2020 9793 9711 0.4978979 19504
07005 2000-2004 2020 1281 1230 0.4898447 2511
04001 2000-2004 2020 2426 2584 0.5157685 5010
23004 2000-2004 2020 9936 10122 0.5046366 20058
28043 2000-2004 2020 875 856 0.4945118 1731
20550 2000-2004 2020 209 228 0.5217391 437
20478 2000-2004 2020 41 44 0.5176471 85
30057 2000-2004 2020 702 686 0.4942363 1388
12035 2000-2004 2020 6669 6614 0.4979297 13283
20105 2000-2004 2020 337 292 0.4642289 629
20552 2000-2004 2020 14 17 0.5483871 31
20158 2000-2004 2020 100 117 0.5391705 217
20355 2000-2004 2020 27 21 0.4375000 48
14015 2000-2004 2020 2759 2826 0.5059982 5585
21087 2000-2004 2020 560 585 0.5109170 1145
07020 2000-2004 2020 2260 2304 0.5048203 4564
07052 2000-2004 2020 7785 7289 0.4835478 15074
16087 2000-2004 2020 642 626 0.4936909 1268
08039 2000-2004 2020 157 165 0.5124224 322
25018 2000-2004 2020 6806 7106 0.5107821 13912
26037 2000-2004 2020 30 37 0.5522388 67
12053 2000-2004 2020 2268 2264 0.4995587 4532
14059 2000-2004 2020 607 594 0.4945878 1201
20412 2000-2004 2020 145 123 0.4589552 268
30037 2000-2004 2020 410 384 0.4836272 794
32002 2000-2004 2020 213 191 0.4727723 404
20278 2000-2004 2020 1515 1579 0.5103426 3094
05013 2000-2004 2020 75 89 0.5426829 164
17018 2000-2004 2020 5461 5326 0.4937425 10787
19038 2000-2004 2020 2973 3079 0.5087574 6052
", header=FALSE)
colnames(sexratios) <- c("fips","period","year","male","female","share_male","total")
auctions$bidders
auctions$bidders
auctions$finalprice
beta1=cov(auctions$bidders, auctions$finalprice)/var(auctions$bidders)
beta0=mean(auctions$finalprice)-beta1*mean(auctions$bidders)
beta1
beta0
#or code for linear regression in R
x=lm(finalprice ~ bidders, data = auctions) #lm stands for linear model. the formula has form y~x and then we put data.
summary(x)
# Plug into the formula: beta0 + beta1*6
beta0 + beta1*6
beta1=cor(houseprices$lotarea, houseprices$saleprice)*sd(houseprices$saleprice)/sd(houseprices$lotarea)
beta0=mean(houseprices$saleprice)-beta1*mean(houseprices$lotarea)
yhat=beta0 + beta1*houseprices$lotarea
#or code for linear regression in R
x=lm(saleprice ~ lotarea, data = houseprices) #lm stands for linear model. the formula has form y~x and then we put data.
summary(x)
yhat=1.566e+05 + 2.113e+00*houseprices$lotarea
yhat=1.566e+05 + 2.113e+00*houseprices$lotarea
#or
x=lm(saleprice ~ lotarea, data = houseprices)
yhat=1.566e+05 + 2.113e+00*houseprices$lotarea
yhat
yhat=x$fitted.values #here you will find predicted values (yhats)
e=houseprices$saleprice - yhat
e
plot(houseprices$lotarea, yhat)
# Use ggplot2 to plot bmi_h (y) vs bmi_w (x)
# Hint: ggplot(married, aes(x = bmi_w, y = bmi_h)) + geom_point()
plot(married$bmi_h, married$bmi_w)
x=lm(bmi_h ~ bmi_w, data = married) #lm stands for linear model. the formula has form y~x and then we put data.
summary(x)
# Run a regression of saleprice on lotarea
x=lm(saleprice ~ lotarea, data = houseprices)
summary(x)
R2=SSR/SST
R2
y=houseprices$saleprice
SST <- sum((y - my)^2)
SSR <- sum((yhat - my)^2)
SSE <- sum((y - yhat)^2) #or sum(e^2)
c(SST = SST, SSR = SSR, SSE = SSE)
R2=SSR/SST
R2
yhat
# Run a regression of saleprice on lotarea
x=lm(saleprice ~ lotarea, data = houseprices)
summary(x)
yhat=x$fitted.values #here you will find predicted values (yhats) #this is just beta0+beta1*x
#you can do
e=houseprices$saleprice - x$fitted.values
#or simply
e=x$residuals #here you will find residuals
y=houseprices$saleprice
SST <- sum((y - my)^2)
SSR <- sum((yhat - my)^2)
SSE <- sum((y - yhat)^2) #or sum(e^2)
c(SST = SST, SSR = SSR, SSE = SSE)
R2=SSE/SST
R2
yhat=x$fitted.values
yhat
my=mean(houseprices$saleprice)
y=houseprices$saleprice
my=mean(houseprices$saleprice)
y=houseprices$saleprice
SST <- sum((y - my)^2)
SSR <- sum((yhat - my)^2)
SSE <- sum((y - yhat)^2) #or sum(e^2)
c(SST = SST, SSR = SSR, SSE = SSE)
R2=SSR/SST
R2
# Run a regression of finalprice on bidders from the auctions dataset
x=lm(saleprice ~ lotarea, data = houseprices)
summary(x)
# Run a regression of finalprice on bidders from the auctions dataset
x=lm(finalprice ~ bidders, data = auctions)
summary(x)
SSR <- sum((yhat - my)^2)
x=lm(finalprice ~ bidders, data = auctions)
summary(x)
yhat=x$fitted.values #here you will find predicted values (yhats) #this is just beta0+beta1*x
e=x$residuals
my=mean(auctions$finalprice)
y=auctions$finalprice
SST <- sum((y - my)^2)
SSR <- sum((yhat - my)^2)
R2=SSR/SST
R2
# Run a regression of family income (dollars) on husband's age (years)
x=lm(famincome ~ age_h, data = married)
#using basic r, visuals true points and line
plot(married$age_h, married$famincome)
points(married$age_h, yhat, col="red", pch=20
points(married$age_h, yhat, col="red", pch=20)
points(married$age_h, yhat, col="red", pch=20)
plot(married$age_h, yhat, col="red", pch=20)
yhat=x$fitted.values
#using basic r, visuals true points and line
plot(married$age_h, married$famincome)
plot(married$age_h, yhat, col="red", pch=20)
#using basic r, visuals true points and line
plot(married$age_h, married$famincome)
# scatterplot of the true data
plot(married$age_h, married$famincome,
xlab = "Age of husband", ylab = "Family income",
pch = 16, col = "black")
# add the fitted line or points
lines(married$age_h, yhat, col = "red", lwd = 2)
married$famincome_thousands = married$famincome / 1000
lm(famincome_thousands ~ age_h, data = married)
ggplot(married, aes(x = age_h, y = famincome_thousands)) +
geom_point(alpha=0.2) +
geom_smooth(method="lm", se=FALSE, color="blue") +
labs(x="Husband's age (years)", y="Family income (thousands of $)")
ggplot(married, aes(x = age_h, y = famincome_thousands)) +
geom_point(alpha=0.2) +
geom_smooth(method="lm", se=FALSE, color="blue") +
labs(x="Husband's age (years)", y="Family income (thousands of $)")
married$age_h_months = married$age_h * 12
lm(famincome_thousands ~ age_h_months, data = married)
ggplot(married, aes(x = age_h_months, y = famincome_thousands)) +
geom_point(alpha=0.2) +
geom_smooth(method="lm", se=FALSE, color="blue") +
labs(x="Husband's age (months)", y="Family income (thousands of $)")
ggplot(married, aes(x = age_h_months, y = famincome_thousands)) +
geom_point(alpha=0.2) +
geom_smooth(method="lm", se=FALSE, color="blue") +
labs(x="Husband's age (months)", y="Family income (thousands of $)")
# Step 0: fit regression (keep your variable names)
reg = lm(saleprice ~ lotarea, data = houseprices)
summary(reg)
# Step 1: core pieces
y    = houseprices$saleprice
yhat = reg$fitted.values
e    = y - yhat
n    = length(y)
# Step 2: compute Sxx
x    = houseprices$lotarea
mx   = mean(x)
Sxx  = sum((x - mx)^2)
# Step 3: error variance estimator
SSE  = sum(e^2)
sigma2_hat = SSE/(n-2)
# Step 4: variances of OLS estimators
var_beta1 = sigma2_hat / Sxx
# Step 5: standard errors of OLS estimators
se_beta1 = sqrt(var_beta1)
se_beta1
#let's multiply y by 1000 and see how standard error changes
houseprices$saleprice_thousands = houseprices$saleprice / 1000
reg2 = lm(saleprice_thousands ~ lotarea, data = houseprices)
summary(reg2)
x=lm(medical_costs ~ male, data = hrs)
summary(x)
x=lm(medical_costs ~ male, data = hrs)
summary(x)
t_stat= (beta1-0)/se_beta1
t_stat
length(hrs$medical_costs)-2
p_value=pt(t_stat, df=length(hrs$medical_costs)-2) #left tail
p_value
p_value=1-pt(t_stat, df=length(hrs$medical_costs)-2) #left tail
p_value
reg1=lm(earnwk ~ educ, data = cps)
summary(reg1)
reg1
t_critical=qt(1-alpha/2, df=length(cps$earnwk)-2)
alpha=0.01
t_critical=qt(1-alpha/2, df=length(cps$earnwk)-2)
t_critical
t_critical
#99% CI for beta1
lower_bound_beta1 = beta1 - t_critical * se_beta1
#99% CI for beta1
lower_bound_beta1 = beta1 - t_critical * se_beta1
upper_bound_beta1 = beta1 + t_critical * se_beta1
c(lower_bound_beta1, upper_bound_beta1)
beta1=101.550
se_beta1=5.575
beta0=-330.753
se_beta0=72.713
#99% CI for beta1
lower_bound_beta1 = beta1 - t_critical * se_beta1
upper_bound_beta1 = beta1 + t_critical * se_beta1
c(lower_bound_beta1, upper_bound_beta1)
reg=lm(medical_costs ~ age, data = hrs)
summary(reg)
beta1=35.894
se_beta1=5.577
beta0=-710.491
se_beta0=402.993
x0=55
x0=55
yhat=-710.491 + 35.894*55
yhat
#hint: to get the vector of residuals you can write: residuals(model)
reg=lm(medical_costs ~ age, data = hrs)
e=residuals(reg)
n=length(hrs$medical_costs)
# Step 1: compute Sxx
x=hrs$age
mx=mean(x)
Sxx=sum((x - mx)^2)
# Step 2: compute sigma hat
SSE=sum(e^2)
sigma2_hat=SSE/(n-2)
# Step 3: compute the critical value for 95% CI
alpha=0.05
t_critical=qt(1-alpha/2, df=n-2)
t_critical
# Step 4: compute the margin of error
```
# Step 4: compute the margin of error
margin_of_error = t_critical * sqrt(sigma2_hat * (1/n + (
# Step 4: compute the margin of error
margin_of_error = t_critical * sqrt(sigma2_hat * (1/n + (x0 - mx)^2 / Sxx))
margin_of_error
# Step 4: compute the margin of error
margin_of_error = t_critical * sqrt(sigma2_hat * (1/n + (x0 - mx)^2 / Sxx))
margin_of_error
# Step 5: compute the confidence interval
lower_bound = yhat - margin_of_error
upper_bound = yhat + margin_of_error
c(lower_bound, upper_bound)
reg=lm(saleprice ~ fullbath, data = houseprices)
summary(reg)
x0=3
yhat=48106 + 86359*3
sigma=summary(reg)$sigma
n=length(houseprices$saleprice)
Sxx=sum((sexratios$total - mean(sexratios$total))^2)
Sxx=sum((x - mx)^2)
#hint: to get sigma: summary(model)$sigma
reg=lm(saleprice ~ fullbath, data = houseprices)
sigma=summary(reg)$sigma
n=length(houseprices$saleprice)
# Step 1: compute Sxx
x=houseprices$fullbath
mx=mean(x)
Sxx=sum((x - mx)^2)
# Step 2: compute sigma hat
#sigma is already computed above
# Step 3: compute the critical value for 95% CI
alpha=0.05
t_critical=qt(1-alpha/2, df=n-2)
t_critical
# Step 4: compute the margin of error
margin_of_error = t_critical * sqrt(sigma^2 * (1 + 1/n + (x0 - mx)^2 / Sxx))
margin_of_error
# Step 5: compute the confidence interval
lower_bound = yhat - margin_of_error
upper_bound = yhat + margin_of_error
c(lower_bound, upper_bound)
# Histogram of residuals
hist(resid)
m1 <- lm(return_5yr ~ expense_ratio, data = mutualfunds)
summary(m1)
resid=m1$residuals
# Histogram of residuals
hist(resid)
#calculate the skewness
skewness = (1/n * sum(deviations^3)) / ( (1/n * sum(deviations^2))^(3/2) )
#calculate the excess curtosis
excess_kurtosis = (1/n * sum(deviations^4)) / ( (1/n * sum(deviations^2))^2 ) - 3
#calculae the JB statistic
JB = n/6 * (skewness^2 + excess_kurtosis^2 / 4)
m1 <- lm(return_5yr ~ expense_ratio, data = mutualfunds)
summary(m1)
resid=m1$residuals
# Histogram of residuals
hist(resid)
deviations=resid - mean(resid)
n=length(resid)
#calculate the skewness
skewness = (1/n * sum(deviations^3)) / ( (1/n * sum(deviations^2))^(3/2) )
#calculate the excess curtosis
excess_kurtosis = (1/n * sum(deviations^4)) / ( (1/n * sum(deviations^2))^2 ) - 3
#calculae the JB statistic
JB = n/6 * (skewness^2 + excess_kurtosis^2 / 4)
##compare to chi square with 2 degrees of freedom  -  pchisq(value, df=df) gives cdf of chi square with df degrees of freedom
p_value = 1 - pchisq(JB, df=2)
JB
p_value
library(tseries)
jarque.bera.test(resid)
SSE = 52
SST = 152
SSR = SST - SSE
n = 15
k = 1 #number of predictors
F_stat = (SSR/k) / (SSE/(n-k-1))
F_stat
p_value = 1 - pf(F_stat, df1=k, df2=n-k-1)
p_value
m1 <- lm(return_5yr ~ fund_age, data = mutualfunds)
anova(m1)
