---
title: 'Class 2d: Review of concepts in Probability and Statistics'
author: "Business Forecasting"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: true
      fig.retina: 2
---   
<style type="text/css">
.remark-slide-content {
    font-size: 20px;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi=300)
library(shiny)
library(ggplot2)
library(forecast)
library(plotly)
library(dplyr)
library(igraph)
library(reshape)
library(spData)
library(leaflet)
library(readr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(hrbrthemes)
library(viridis)
library(reshape2)
library(gapminder)
library(knitr)
library(kableExtra)
library(DT)
library(patchwork)
options(scipen = 999)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(base_color = "#43418A", 
colors = c(
  red = "#f34213",
  purple = "#3e2f5b",
  orange = "#ff8811",
  green = "#136f63",
  blue = "#1E90FF",
  white = "#FFFFFF"
))
```


```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(dplyr)
load("Data/Health_data.Rda")

```


---

layout: false
class: inverse, middle
# Methods of Qualitative Forecasting



---
### Delphi Method
- A structured communication process to reach a consensus for complex, uncertain and long terms forecasting tasks
  1. Select a group of experts
  2. Invite them to the study. They are anonymous and don't talk to each other!
  3. Ask them to answer a questionnaire
  4. Get initial responses
  5. Compile them into summary
  6. Send them summary and get their feedback with refined answers
  7. Reiterate until consensus is reached or no further improvement



--
#### Example: Determining AI threats
- What are the risks of AI developments?
- Panel of experts from academia and industry
  - Computer scientists, engineers, CEOs of AI companies, ethic experts
- Send them questionnaires asking about potential threats
- Compile responses into summary and send them back
- Get more rounds of responses until consensus
- Identify the most probable risks

---

### Brainstorming
- Creative technique for generating ideas.
- Encourages free thinking and building on suggestions.
- Appropriate for exploring possibilities.
  - Form a group (no need for experts)
  - State the problem
  - Encourage ideas, no matter how crazy
  - Build and combine each others' ideas
  - Document the ideas and synthesize them


--
#### Example: Enhancing Employee Engagement
- Tech company's HR department.
- Representatives from HR, IT, and different departments.
- Generate ideas for a mobile app to enhance employee engagement.
- Write them down and implement the relevant ones

---

### Panel of Experts
- Assemble knowledgeable individuals
  - At the same time and spot
- They meet,  offer insights and expertise, and discuss
- Aid in well-informed decisions.
- Sometimes ends up with a report with conculsions


--
#### Example: Environmental Policy Formulation
- Government agency want to find identify and address most pressing environmental issues
- Environmental scientists, economists, conservationists, and policymakers.
- Discuss policy options.
- Create comprehensive environmental policies.

---

### Focus Groups
- Gather diverse participant - not necessarily experts
- Share perceptions, attitudes, and opinions.
- Provide qualitative data and consumer insights.


--
#### Example: Market Research for a New TV SHOW
- Proposing a new TV Show and trying to see how well it will do
- Participants from various demographics.
- Understand consumers' preferences and perceptions about the TV show
- Fine-tune the product and marketing strategy.

---



---
layout: false
class: inverse, middle

# Types of Data

---

### Longitudinal Data
- Observations are collected for the same subject (entity) over a period of time
- Same as time series data
- Example: Tracking a company's annual revenue and number of employees over several years

#### Longitudinal Data Example

```{r}
# Load the DT package
library(DT)

# Create the data frame
longitudinal_data <- data.frame(
  Year = 2018:2022,
  Revenue = c(50000, 52000, 55000, 58000, 60000),
  Employees = c(50, 55, 60, 65, 70)
)

# Display the data table
datatable(longitudinal_data,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

- Another Example: Share of people with Diabetes in Mexico in years 2010, 2015, 2020

---

### Cross-Sectional Data
- Observations are collected at a single point in time
- Example: A survey of customers' satisfaction with a product and likelihood of repurchase at a certain point in time

#### Cross-Sectional Data Example

```{r}
# Create the data frame
cross_sectional_data <- data.frame(
  Customer_ID = 1:4,
  Satisfaction_Score = c(7, 8, 5, 9),
  Repurchase_Likelihood = c('Likely', 'Unlikely', 'Likely', 'Likely')
)

# Display the data table
datatable(cross_sectional_data,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

- Another Example: Share of people with Diabetes in 2010 in Mexico, USA, Canada, Brazil

---

### Panel Data
- Combines both longitudinal and cross-sectional data 
- Observations are collected for multiple subjects over multiple points in time
- Example: Tracking the annual revenue and number of employees of several companies over a few years

#### Panel Data Example


```{r}
# Create the data frame
panel_data <- data.frame(
  Year = rep(2018:2022, each = 3),
  Company = rep(c('A', 'B', 'C'), times = 5),
  Revenue = c(50000, 52000, 55000, 58000, 60000,
              60000, 63000, 65000, 68000, 70000,
              70000, 72000, 75000, 78000, 80000),
  Employees = c(50, 55, 60, 65, 70,
                100, 105, 110, 115, 120,
                150, 155, 160, 165, 170)
)

# Display the data table
datatable(panel_data,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

- Another Example: Share of people with Diabetes in Mexico, USA, Canada, Brazil, each country in years 2010, 2015, 2020

---
## Q1

```{r}
# Create the data frame
data1 <- data.frame(
  Month = rep(c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'), each = 3),
  Cryptocurrency = rep(c('Bitcoin', 'Ethereum', 'Dogecoin'), times = 12),
  Market_Cap = c(60000, 40000, 10000, 62000, 41000, 10500, 63000, 42000, 11000, 
                  64000, 43000, 11500, 65000, 44000, 12000, 66000, 45000, 12500, 
                  67000, 46000, 13000, 68000, 47000, 13500, 69000, 48000, 14000, 
                  70000, 49000, 14500, 71000, 50000, 15000, 72000, 51000, 15500)
)

# Display the data table
datatable(data1,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```



--

**Panel data**
- Multiple time observation per subject (currency) and multiple subjects

---

## Q2


```{r}
# Create the data frame
data2 <- data.frame(
  Country = c('United States', 'China', 'India', 'Brazil', 'Russia'),
  Population_Millions = c(331, 1439, 1380, 213, 145),
  GDP_Billions = c(21433, 15308, 3160, 1848, 1690),
  Internet_Users_Millions = c(246, 904, 560, 126, 116)
)

# Display the data table
datatable(data2,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```


--

**Cross-sectional data**
- Single (time) observation per subject (user), many subjects

---

## Q3


```{r}
# Create the data frame
data3 <- data.frame(
  Year = 2020:2024,
  Electric_Car_Sales = c(20000, 30000, 40000, 50000, 60000)
)

# Display the data table
datatable(data3,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

--

**Longitudinal data** 
- Multiple (time) observations of a single subject


---

layout: false
class: inverse, middle
## Variable Types

---



## Variable Types

We have two general types: .blue[Categorical] and .blue[Numerical] variables

### Categorical Variables

- Variables that can be divided into one or more groups or categories.
  - **Ordinal:** These variables can be logically ordered or ranked. 
      - *Variable:* Customer Satisfaction Survey Results
      - *Example:* Very Unsatisfied, Unsatisfied, Neutral, Satisfied, Very Satisfied

  - **Nominal:** These variables cannot be ordered or ranked. 
      - *Variable:* Social Media Platforms Used
      - *Example:* Facebook, Instagram, Twitter, LinkedIn, TikTok, Snapchat

---

### Numerical Variables

- Variables that hold numeric value and ordering is possible
  - **Discrete:** These variables can only take certain values
      - *Example*: Number of App Downloads from App Store
      - *Example*: Number of children you have
      - *Example*: Size of coke products: 0.33L, 0.5L, 1L, 2.25L 
      
      
<center>
<img src=coke_sizes.jpg width="500">
</center>

---
### Numerical Variables

- Variables that hold numeric value and ordering is possible
  - **Discrete:** These variables can only take certain values
      - *Example*: Number of App Downloads from App Store
      - *Example*: Number of children you have
      - *Example*: Size of coke products
      


  - **Continuous:** These variables can take any value within a range
      - *Example*: Time spent on a Webpage
      - *Example*: Exchange rate between MXN and USD

--

  - What's the main difference between ordinal and discrete?
    - We could say 1=Very unsatisfied, 2=Unsatisfied
    - But we cannot say that very unsatisfied has half of satisfaction of person who is just unsatisfied!
    - We can order, but these numbers don't have meaning in terms of distance between them


---

### Mexican Health Survey
- Representative sample of the Mexican population .red[n=37858]. 
- We will use it to investigate market for Ozempic

```{r Sales_forecast_3, echo=FALSE, warning=FALSE}


datatable(Health_data,
          fillContainer = FALSE,
          options = list(
            pageLength = 5,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)

```

--
- *Age*: Numerical, Discrete

--
- *Gender*: Categorical, Nominal

--
- *Weight*: Numerical, Continuous

--
- *Location_type*: Categorical, Nominal

--
- *Diabetes*: Categorical, Nominal

--
- *Mother_diabetes*: Categorical, Nominal

--
- *Difficulty_walking*: Categorical, Ordinal


---
layout: false
class: inverse, middle

# Summarizing Data 

## Graphical summaries

---

### Categorical variables
###Frequency Tables

**Frequency table**: present the absolute frequencies (counts) and relative frequencies (shares) of each category. 
- Categories are mutually exclusive and collectively exhaustive
- Relative frequency of category $i$: $p_i=\frac{n_i}{N}$
    - $n_i$ is count of category $i$
    - $N$ is total count in the sample

.pull-left[
```{r, warning=FALSE}
# Load necessary libraries
library(dplyr)
library(knitr)

# Assume we have a categorical variable in a data frame
frequency_table <- table(Health_data$location)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Category', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)
frequency_table$Category=as.character(frequency_table$Category)
frequency_table_l=frequency_table
# Generate frequency table
total_row <- c('Total', sum(frequency_table$n_i), sum(frequency_table$p_i))
frequency_table1 <- rbind(frequency_table, total_row)


# Display the table
datatable(frequency_table1,
          fillContainer = FALSE,
          options = list(
            pageLength = 8,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '15px'});",
              "$(this.api().table().container()).find('caption').css({'font-size': '18px'});", # Add this line for caption size
              "}"
            )
          ),
          rownames = FALSE, caption = "Location")
```
]

.pull-right[
```{r, warning=FALSE}
# Load necessary libraries
library(dplyr)
library(knitr)

# Assume we have a categorical variable in a data frame
frequency_table <- table(Health_data$Difficulty_walking)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Category', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)
frequency_table$Category=as.character(frequency_table$Category)
frequency_table_o=frequency_table
# Generate frequency table
total_row <- c('Total', sum(frequency_table$n_i), sum(frequency_table$p_i))
frequency_table1 <- rbind(frequency_table, total_row)


# Display the table
datatable(frequency_table1,
          fillContainer = FALSE,
          options = list(
            pageLength = 8,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '15px'});",
              "$(this.api().table().container()).find('caption').css({'font-size': '18px'});", # Add this line for caption size
              "}"
            )
          ),
          rownames = FALSE, caption = "Difficulty Waking")
```
]
---
###Bar Charts
**Bar charts** visually represents the frequency count of each category

.center[
```{r, warning=FALSE, fig.height=4.2}
# Load necessary libraries
frequency_table <- frequency_table %>%
  arrange(desc(n_i))

# Generate interactive bar chart
ggplot(frequency_table, aes(x = reorder(Category, -n_i), y = n_i, fill = Category)) +
  geom_bar(stat = 'identity', width = 0.7, color = 'white') +
  geom_text(aes(label = n_i), vjust = -0.01, size = 4, color = 'black') +
  labs( x = "Category", y = "Count") +
  theme_xaringan() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )+ scale_xaringan_fill_discrete()

```
]
---
###Bar Charts
**Bar charts** visually represents the frequency count of each category

.center[
```{r, warning=FALSE, fig.height=4.2}
# Load necessary libraries
frequency_table <- frequency_table %>%
  arrange(desc(n_i))

# Generate interactive bar chart
ggplot(frequency_table, aes(x = reorder(Category, -p_i), y = p_i, fill = Category)) +
  geom_bar(stat = 'identity', width = 0.7, color = 'white') +
  geom_text(aes(label = p_i), vjust = -0.01, size = 4, color = 'black') +
  labs( x = "Category", y = "Share") +
  theme_xaringan() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )+ scale_xaringan_fill_discrete()



```
]
---


### More Creative Bar Chart

<center>
<img src=Bar_chart_food_poisoning.png width="800">
</center>


---
###Pie Charts
**Pie chart**: Each slice is proportional to the category's frequency


.center[
```{r, warning=FALSE}
# Generate interactive pie chart
plot_ly(frequency_table_l, labels = ~Category, values = ~n_i, type = 'pie',
        textposition = 'inside', insidetextorientation = 'radial',
        width = 800,   # Adjust the width according to your preference
        height = 400) %>%
  layout(title = list(text = "Location", y = 0.95),  # Move title slightly up
         font = list(size = 18),  # Increase font size here as needed
         legend = list(orientation = 'h', y = -0.2),  # Set y to negative value for bottom position
         margin = list(l = 50, r = 50, b = 50, t = 100),  # Adjust margins
         showlegend = TRUE  # Ensure legend is shown
  )
```
]
---
###Pie Charts
**Pie chart**: (Angle of) Each slice is proportional to the category's frequency


.center[
```{r, warning=FALSE}
# Generate interactive pie chart
plot_ly(frequency_table_o, labels = ~Category, values = ~n_i, type = 'pie',
        textposition = 'inside', insidetextorientation = 'radial',
        width = 800,   # Adjust the width according to your preference
        height = 400) %>%
  layout(title = list(text = "Difficulty Walking", y = 0.95),  # Move title slightly up
         font = list(size = 18),  # Increase font size here as needed
         legend = list(orientation = 'h', y = -0.2),  # Set y to negative value for bottom position
         margin = list(l = 50, r = 50, b = 50, t = 100),  # Adjust margins
         showlegend = TRUE  # Ensure legend is shown
  )
```
]
---

### My favorite pie chart

<center>
<img src=Netflix_pie_chart.jpg width="800">
</center>

---

### Frequency Distribution
Suppose we survey people age 30-50 how many partners they had in their life. 
- What's the distribution of partners?
- Calculate relative frequencies
- Show them on a bar graph

.pull-left[
#### Data

```{r}
# Load necessary libraries
library(dplyr)
library(knitr)

## Set seed for reproducibility
set.seed(42)

# Create a dataset with 50 observations
small_data <- data.frame(
  Physician = factor(paste("Dr.", 1:150, sep = "")),  # Unique physician name
Lifelong_Partners = c(sample(c(0, 1), 10, replace = TRUE), round(rlnorm(130, meanlog = 1.5, sdlog = 0.5)), round(runif(10, min = 1, max = 50))) # Synthetic data for number of lifelong sexual partners
)

frequency_table <- table(small_data$Lifelong_Partners)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Number_of_partners', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)
frequency_table$Number_of_partners=as.character(frequency_table$Number_of_partners)
frequency_table_o=frequency_table
# Generate frequency table
total_row <- c('Total', sum(frequency_table$n_i), sum(frequency_table$p_i))
frequency_table1 <- rbind(frequency_table, total_row)
frequency_table$Number_of_partners=as.numeric(frequency_table$Number_of_partners)
frequency_table$p_i=as.numeric(frequency_table$p_i)

# Display the data
datatable(frequency_table1,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```
]

.pull-right[
####Distribution

```{r, out.width='100%', fig.height=6, warning=FALSE}

ggplot(frequency_table[frequency_table$Number_of_partners!="Total",], aes(x = Number_of_partners, y = p_i, fill = factor(Number_of_partners)))+
  geom_bar(stat = "identity") +
  labs(title = "Frequency of Number of Partners", x = "Number of partners", y = "Frequency")+
  theme_xaringan()+
  theme(legend.position="none")+ scale_xaringan_fill_discrete()

```
]

---

### Frequency Distribution
We can also show frequency of age of people who have diabetes from our data

```{r, out.width='100%', fig.height=4, warning=FALSE}
frequency_table <- table(Health_data[Health_data$diabetes==1,]$age)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Age', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)

ggplot(frequency_table, aes(x = as.numeric(as.character(Age)), y = p_i))+
  geom_bar(stat = "identity", position = "identity") +
  labs(title = "Frequency of Age", x = "Age", y = "Frequency")+
  theme_xaringan()+
  theme(legend.position="none")+xlim(15,100)+ylim(0,0.035)

```



---


### Frequency Distribution
Compare it to the age distribution in the adult population (20+)


```{r, out.width='100%', fig.height=4, warning=FALSE}
frequency_table <- table(Health_data$age)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Age', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)

ggplot(frequency_table, aes(x = as.numeric(as.character(Age)), y = p_i))+
  geom_bar(stat = "identity", position = "identity") +
  labs(title = "Frequency of Age", x = "Age", y = "Frequency")+
  theme_xaringan()+
  theme(legend.position="none")+xlim(15,100)+ylim(0,0.035)

```


---


## Numerical Variables: Continuous
- What about continuous values? Why can't we do the same?

.pull-left[
```{r, echo=FALSE, fig.height=7, warning=FALSE}
# Assuming Health_data is the dataset with 'weight' variable

frequency_table <- table(Health_data$weight)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('weight', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table1=frequency_table

frequency_table$p_i <- round(prop.table(frequency_table$n_i), 7)

ggplot(frequency_table1, aes(x = as.numeric(as.character(weight)), y = p_i))+
  geom_bar(stat = "identity", position = "identity") +
  labs(title = "Frequency of weight", x = "weight", y = "Frequency")+
  theme_xaringan()+
  theme(legend.position="none")

```
]

.pull-right[
```{r, echo=FALSE, fig.height=7,  warning=FALSE}

datatable(frequency_table,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

]


- Most values never repeat, so they have very low relative frequency

---
## Histograms

**Solution**: Group similar values together
- Construct intervals and show how many observations are in a given interval

--

**Process**
  1. Decide how many intervals 
  2. And how wide they are
  3. Then calculate the absolute and relative frequencies of each interval
  4. Plot it with bars 
  
--

---

**My approach**
  - I want $k$ (example $k$=5) equal intervals
  
--
  
  - Divide the range of the data into $k$ equal intervals
    
--
  
      - *Range* is max-min of the data
        
--
  
```{r, echo=TRUE}
# Calculate max and min
max_value <- max(Health_data$weight)
min_value <- min(Health_data$weight)

# Calculate the difference
range <- max_value - min_value
```
  
--
  
```{r}
# Calculate the difference
print(paste("Range=",max_value,"-",min_value,"=",range))
```
  
--
  
- With 5 intervals, each will be 32kg wide
--
  
- The first one starts at the minimum value (30.3745)
--
  
- The last one ends at the maximum value (190.8078)
--

- Calculate how many observations I have in each interval and what's the relative frequency

---

## Histograms

- Midpoint represents middle of the interval - center of the bar
- $P_i$ is cumulative frequency: share of observations in this or smaller interval
  - *Example*: $P_{(62.46-94.55)}=0.911$  
  - *Interpretation*: 91.1% of people have weight lower than 94.55kg


.pull-left[
```{r, echo=FALSE, fig.height=7, warning=FALSE}
# Assuming Health_data is the dataset with 'weight' variable
ggplot(Health_data, aes(x = weight)) +
  geom_histogram(aes(y = after_stat(count / sum(count))),breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =6), color = "black") +
  labs(title = "Histogram with 5 Classes", x = "Weight", y = "Frequency") +
  theme_xaringan()
```
]

.pull-right[
```{r, echo=FALSE, fig.height=7,  warning=FALSE}

# Create the frequency table
hist_data <- ggplot_build(ggplot(Health_data, aes(x = weight)) +
  geom_histogram(breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =6)))
interval_values <- paste(round(hist_data$data[[1]]$xmin, 2), "-", round(hist_data$data[[1]]$xmax, 2))
freq_table <- data.frame(
  Interval = interval_values,
  Midpoint = round(round(hist_data$data[[1]]$xmin, 2)+round(round(hist_data$data[[1]]$xmax, 2) - round(hist_data$data[[1]]$xmin, 2),2)/2,2),
  n_i = hist_data$data[[1]]$count,
  p_i = round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7),
  P_i =cumsum(round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7))
)

datatable(freq_table,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

]


---
## Histogram with 10 Classes

Now, let's increase the number of classes to 10. 

.pull-left[
```{r, echo=FALSE, fig.height=7, warning=FALSE}
# Assuming Health_data is the dataset with 'weight' variable
ggplot(Health_data, aes(x = weight)) +
  geom_histogram(aes(y = after_stat(count / sum(count))), breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =11), color = "black") +
  labs(title = "", x = "Weight", y = "Absolute Frequency") +
  theme_xaringan()
```
]

.pull-right[
```{r, echo=FALSE, fig.height=7,  warning=FALSE}

# Create the frequency table
hist_data <- ggplot_build(ggplot(Health_data, aes(x = weight)) +
  geom_histogram(breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =11)))
interval_values <- paste(round(hist_data$data[[1]]$xmin, 2), "-", round(hist_data$data[[1]]$xmax, 2))
freq_table <- data.frame(
  Interval = interval_values,
  Midpoint = round(round(hist_data$data[[1]]$xmin, 2)+round(round(hist_data$data[[1]]$xmax, 2) - round(hist_data$data[[1]]$xmin, 2),2)/2,2),
  n_i = hist_data$data[[1]]$count,
  p_i = round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7),
  P_i =cumsum(round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7))
)

datatable(freq_table,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```

]
---
## Histogram with 100 Classes

.pull-left[
```{r, echo=FALSE, fig.height=7, warning=FALSE}
# Assuming Health_data is the dataset with 'weight' variable
ggplot(Health_data, aes(x = weight)) +
  geom_histogram(aes(y = after_stat(count / sum(count))), breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =101), color = "black") +
  labs(title = "", x = "Weight", y = "Frequency") +
  theme_xaringan()
```
]

.pull-right[
```{r, echo=FALSE, fig.height=7,  warning=FALSE}

# Create the frequency table
hist_data <- ggplot_build(ggplot(Health_data, aes(x = weight)) +
  geom_histogram(breaks = seq(min(Health_data$weight), max(Health_data$weight), length.out =101)))
interval_values <- paste(round(hist_data$data[[1]]$xmin, 2), "-", round(hist_data$data[[1]]$xmax, 2))
freq_table <- data.frame(
  Interval = interval_values,
  Midpoint = round(round(hist_data$data[[1]]$xmin, 2)+round(round(hist_data$data[[1]]$xmax, 2) - round(hist_data$data[[1]]$xmin, 2),2)/2,2),
  n_i = hist_data$data[[1]]$count,
  p_i = round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7),
  P_i =cumsum(round(hist_data$data[[1]]$count / sum(hist_data$data[[1]]$count),7))
)

datatable(freq_table,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```
]


- Helps to see the distribution and outliers 
- Is more always better?
- With smaller intervals, histogram tends to the **probability density function** 



---

## Probability Density Function (PDF)

### Definition
- **Probability Density Function (pdf)**  describes the probability distribution of a continuous random variable. 
- It **does not** give probability at a given value (this is always 0 for continous variable)
- It shows which in which intervals that variable the most often appears
- It is used to calculate the probability of the random variable being in a given interval
- Area under it always adds up to 1

--

### Example
We have a random variable X representing the weight of adults in Mexican population. The PDF of X  helps to describe the likelihood of finding a person of a specific weight within a range (e.g., between 58kg and 60kg).

---

### How They Work
To calculate the probability of X falling within a specific range [a, b], you need to integrate the PDF from a to b:

$P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx$

What is the share of population with weight between 65kg and 75kg?

```{r, echo=FALSE, fig.height=5, out.width='100%',  warning=FALSE}
# Load the required libraries
library(plotly)

# Function to calculate PDF for the normal distribution
pdf_normal <- function(x, mean, sd) {
  return(dnorm(x, mean = mean, sd = sd))
}

# Function to calculate the probability of X falling within a specific range [a, b]
prob_within_range <- function(a, b, mean, sd) {
  return(integrate(pdf_normal, lower = a, upper = b, mean = mean, sd = sd)$value)
}

# Parameters for the weight distribution in Mexico
mean_weight <- 70
sd_weight <- 10

# Generate x values for the plot (weight range from 40 kg to 100 kg)
x <- seq(40, 100, length.out = 100)

# Calculate the PDF values
pdf_values <- pdf_normal(x, mean_weight, sd_weight)

# Create the interactive plot
p <- plot_ly(x = x, y = pdf_values, type = 'scatter', mode = 'lines', line = list(color = 'blue'),
        width = 800,   # Adjust the width according to your preference
        height = 400)

# Function to create filled curve plot for shaded intervals
add_filled_curve <- function(p, a, b) {
  x_fill <- c(a, x[x >= a & x <= b], b)
  y_fill <- c(0, pdf_values[x >= a & x <= b], 0)
  p <- p %>% add_trace(
    x = x_fill,
    y = y_fill,
    type = "scatter",
    fill = "tozeroy",
    fillcolor = "rgba(100, 100, 100, 0.3)",
    line = list(color = "transparent"),
    showlegend = FALSE,
    hoverinfo = "none"
  )
}

# Example 1: Shaded interval [65, 75]
interval_1_prob <- prob_within_range(65, 75, mean_weight, sd_weight)
p <- add_filled_curve(p, 65, 75)
p <- p %>% layout(annotations = list(
  list(
    x = 70,
    y = pdf_normal(70, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = paste("Probability:", round(interval_1_prob, 4)),
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -40
  ),
  list(
    x = 70,
    y = pdf_normal(70, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = "Interval: [65, 75]",
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -60
  )
))
p
```



---


### How They Work
To calculate the probability of X falling within a specific range [a, b], you need to integrate the PDF from a to b:

$P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx$

What is the share of population with weight between 40 and 50kg?
```{r, echo=FALSE, fig.height=5, out.width='100%',  warning=FALSE}

# Example 4: Shaded interval [10, 50]
interval_4_prob <- prob_within_range(40, 50, mean_weight, sd_weight)
p <- plot_ly(x = x, y = pdf_values, type = 'scatter', mode = 'lines', line = list(color = 'blue'),
        width = 800,   # Adjust the width according to your preference
        height = 400)
p <- add_filled_curve(p, 40, 50)
p <- p %>% layout(annotations = list(
  list(
    x = 45,
    y = pdf_normal(45, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = paste("Probability:", round(interval_4_prob, 4)),
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -40
  ),
  list(
    x = 45,
    y = pdf_normal(45, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = "Interval: [40, 50]",
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -60
  )
))
p
```


---

### How They Work
To calculate the probability of X falling within a specific range [a, b], you need to integrate the PDF from a to b:

$P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx$

What is the share of population with weight between 66.99 and 67 kg?

```{r, echo=FALSE, fig.height=5, out.width='100%',  warning=FALSE}


# Example 5: Shaded interval [66, 67]
interval_5_prob <- prob_within_range(66.99, 67, mean_weight, sd_weight)
p <- plot_ly(x = x, y = pdf_values, type = 'scatter', mode = 'lines', line = list(color = 'blue'),
        width = 800,   # Adjust the width according to your preference
        height = 400)
p <- add_filled_curve(p, 66.99, 67)
p <- p %>% layout(annotations = list(
  list(
    x = 66.99,
    y = pdf_normal(66.99, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = paste("Probability:", round(interval_5_prob, 4)),
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -40
  ),
  list(
    x = 66.99,
    y = pdf_normal(66.99, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = "Interval: [66.99, 67]",
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -60
  )
))
p
```

---

### How They Work
To calculate the probability of X falling within a specific range [a, b], you need to integrate the PDF from a to b:

$P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx$

What is the share of population with weight between 40 and 100 kg?

```{r, echo=FALSE, fig.height=5, out.width='100%',  warning=FALSE}


# Example 6: Shaded whole interval [0, 190]
interval_6_prob <- prob_within_range(40, 100, mean_weight, sd_weight)
p <- plot_ly(x = x, y = pdf_values, type = 'scatter', mode = 'lines', line = list(color = 'blue'),
        width = 800,   # Adjust the width according to your preference
        height = 400)
p <- add_filled_curve(p, 40, 100)
p <- p %>% layout(annotations = list(
  list(
    x = 70,
    y = pdf_normal(70, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = paste("Probability:", round(interval_6_prob, 4)),
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -40
  ),
  list(
    x = 70,
    y = pdf_normal(70, mean_weight, sd_weight),
    xref = "x",
    yref = "y",
    text = "Interval: [40, 100]",
    showarrow = TRUE,
    arrowhead = 2,
    ax = 0,
    ay = -60
  )
))

# Display the plot
p


```



---



## Distribution Shapes: Modality

```{r, echo=FALSE, fig.height=4.5, out.width='100%',  warning=FALSE}

# Load the required libraries
library(ggplot2)

# Set a seed for reproducibility
set.seed(42)

# Generate data for each distribution
# Unimodal (Normal Distribution)
unimodal_data <- rnorm(1000, mean = 50, sd = 10)

# Bimodal Distribution
bimodal_data <- c(rnorm(500, mean = 30, sd = 5), rnorm(500, mean = 70, sd = 10))

# Multimodal Distribution
multimodal_data <- c(rnorm(300, mean = 20, sd = 5), rnorm(500, mean = 50, sd = 10), rnorm(200, mean = 80, sd = 5))

# Uniform Distribution
uniform_data <- runif(1000, min = 0, max = 100)

# Create data frames
df_unimodal <- data.frame(Value = unimodal_data, Distribution = "Unimodal")
df_bimodal <- data.frame(Value = bimodal_data, Distribution = "Bimodal")
df_multimodal <- data.frame(Value = multimodal_data, Distribution = "Multimodal")
df_uniform <- data.frame(Value = uniform_data, Distribution = "Uniform")

# Combine data frames
df_combined <- rbind(df_unimodal, df_bimodal, df_multimodal, df_uniform)

# Plot the Probability Density Functions (PDFs)
ggplot(df_combined, aes(x = Value, fill = Distribution)) +
  geom_density(alpha = 0.6) +
  labs(title = "",
       x = "Value", y = "Density") +
  theme_xaringan()+facet_grid(rows=~Distribution)+
  theme(legend.position = "none", axis.text.x = element_blank())


```



---

## Which is uniformaly distributed

 1. Weights of Adult Females
 2. Salaries in Mexico
 3. Airbnb prices in CDMX
 4. Birthdays of Classmates (day of the month)



---

<center>
<img src=Distributions_q_data.png width="800">
</center>


---

## Distribution Shapes: Skewness

```{r, echo=FALSE, fig.height=4.5, out.width='100%',  warning=FALSE}

# Load the required libraries
library(ggplot2)

# Set a seed for reproducibility
set.seed(42)

# Generate data for each distribution
# Skewed Right (Positively Skewed)
skewed_right_data <- c(rexp(1000, rate = 0.2), rexp(200, rate = 0.1))

# Skewed Left (Negatively Skewed, similar to age at death)
skewed_left_data <- -skewed_right_data



# Symmetric Distribution (Triangular Distribution)
symmetric_data <- c(rnorm(1000, mean = 50, sd = 10))

# Create data frames
df_skewed_right <- data.frame(Value = skewed_right_data, Distribution = "Skewed Right")
df_skewed_left <- data.frame(Value = skewed_left_data, Distribution = "Skewed Left")
df_symmetric <- data.frame(Value = symmetric_data, Distribution = "Symmetric")

# Combine data frames
df_combined_skewed <- rbind(df_skewed_right, df_skewed_left, df_symmetric)

# Plot the Probability Density Functions (PDFs) using facet_grid
ggplot(df_combined_skewed, aes(x = Value, fill = Distribution)) +
  geom_density(alpha = 0.6) +
  labs(title = "",
       x = NULL, y = "Density") +  # Set x = NULL to remove x-axis label
  theme_xaringan() +
  facet_grid(rows = ~Distribution, scales = "free_x") +
  theme(legend.position = "none", axis.text.x = element_blank()) 

```

---

### Age at death

<center>
<img src=Age_at_death.jpeg width="800">
</center>

---

#### What if we want to calculate proportion of people who weight less or equal to 50kg?

---

## Cumulative Distribution Function (CDF)


The .blue[Cumulative Distribution Function] (CDF) gives the probability that a random variable X will take on a value less than or equal to a specific value.

For a continuous random variable X with PDF f(x), the CDF F(x) is defined as:

$F(x) = \int_{-\infty}^{x} f(t) \, dt = P(X \leq x)$

Characteristics:
- The CDF starts (for minus infinity) at 0 (minimum)
- It approaches 1 as x approaches infinity (maximum)
- It is non decreasing
- It is right continuous

---

## Example 1: Normal Variable (weight in the population)

$F(50) = \int_{-\infty}^{50} f(t) \, dt = P(X \leq 50)=0.02$

```{r example1, echo=FALSE, fig.width=12, fig.height=5, warning=FALSE}

# Define the transformed PDF and CDF functions
mean_new <- 70
sd_new <- 10

pdf_func_transformed <- function(x) {
  dnorm(x, mean = mean_new, sd = sd_new)
}

cdf_func_transformed <- function(x) {
  pnorm(x, mean = mean_new, sd = sd_new)
}

# Generate data for plotting the transformed distribution
x_transformed <- seq(mean_new - 3 * sd_new, mean_new + 3 * sd_new, length.out = 100)
pdf_y_transformed <- pdf_func_transformed(x_transformed)
cdf_y_transformed <- cdf_func_transformed(x_transformed)

# Create the combined plot for the transformed distribution
pdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, pdf_y_transformed), color = "blue", size = 1.5) +
  geom_area(aes(x = x_transformed[x_transformed <= mean_new - 2 * sd_new], 
                y = pdf_y_transformed[x_transformed <= mean_new - 2 * sd_new]), fill = "lightblue") +
  labs(title = "PDF of Transformed Distribution", x = "X'", y = "Density") +
  theme_minimal()

cdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, cdf_y_transformed), color = "red", size = 1.5) +
  geom_hline(yintercept = cdf_func_transformed(mean_new - 2 * sd_new), linetype = "dashed", color = "black") +
  geom_vline(xintercept = mean_new - 2 * sd_new, linetype = "dashed", color = "black") +
  annotate("text", x = mean_new - 2 * sd_new, 
           y = cdf_func_transformed(mean_new - 2 * sd_new) + 0.01, 
           label = sprintf("%.2f", cdf_func_transformed(mean_new - 2 * sd_new)), 
           vjust = -1, size = 5) +
  labs(title = "CDF of Transformed Distribution", x = "X'", y = "Cumulative Probability") +
  theme_minimal()

grid.arrange(pdf_plot_transformed, cdf_plot_transformed, ncol = 2)
```

---

## Example 2: Normal Variable (weight in the population)

$F(72) = \int_{-\infty}^{72} f(t) \, dt = P(X \leq 72)=0.58$

```{r example2, echo=FALSE, fig.width=12, fig.height=5, warning=FALSE}
# Generate data for plotting
# Define the transformed PDF and CDF functions
mean_new <- 70
sd_new <- 10

pdf_func_transformed <- function(x) {
  dnorm(x, mean = mean_new, sd = sd_new)
}

cdf_func_transformed <- function(x) {
  pnorm(x, mean = mean_new, sd = sd_new)
}

# Generate data for plotting the transformed distribution
x_transformed <- seq(mean_new - 3 * sd_new, mean_new + 3 * sd_new, length.out = 100)
pdf_y_transformed <- pdf_func_transformed(x_transformed)
cdf_y_transformed <- cdf_func_transformed(x_transformed)

# Create the PDF plot for the transformed distribution
pdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, pdf_y_transformed), color = "blue", size = 1.5) +
  geom_area(aes(x = x_transformed[x_transformed <= mean_new + 0.2 * sd_new], 
                y = pdf_y_transformed[x_transformed <= mean_new + 0.2 * sd_new]), fill = "lightblue") +
  labs(title = "PDF of Transformed Distribution", x = "X'", y = "Density") +
  theme_minimal()

# Create the CDF plot for the transformed distribution
cdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, cdf_y_transformed), color = "red", size = 1.5) +
  geom_hline(yintercept = cdf_func_transformed(mean_new + 0.2 * sd_new), linetype = "dashed", color = "black") +
  geom_vline(xintercept = mean_new + 0.2 * sd_new, linetype = "dashed", color = "black") +
  annotate("text", x = mean_new + 0.2 * sd_new, 
           y = cdf_func_transformed(mean_new + 0.2 * sd_new) + 0.01, 
           label = sprintf("%.2f", cdf_func_transformed(mean_new + 0.2 * sd_new)), 
           vjust = -1, size = 5) +
  labs(title = "CDF of Transformed Distribution", x = "X'", y = "Cumulative Probability") +
  theme_minimal()

# Combine the plots
grid.arrange(pdf_plot_transformed, cdf_plot_transformed, ncol = 2)
```

---

## Example 3: Normal Variable (weight in the population)

$F(102) = \int_{-\infty}^{102} f(t) \, dt = P(X \leq 102)=0.99$


```{r example3, echo=FALSE, fig.width=12, fig.height=5, warning=FALSE}
# Generate data for plotting
# Generate data for plotting
mean_new <- 70
sd_new <- 10

pdf_func_transformed <- function(x) {
  dnorm(x, mean = mean_new, sd = sd_new)
}

cdf_func_transformed <- function(x) {
  pnorm(x, mean = mean_new, sd = sd_new)
}

# Generate data for plotting the transformed distribution
x_transformed <- seq(mean_new - 3 * sd_new, mean_new + 3 * sd_new, length.out = 100)
pdf_y_transformed <- pdf_func_transformed(x_transformed)
cdf_y_transformed <- cdf_func_transformed(x_transformed)

# Create the PDF plot for the transformed distribution
pdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, pdf_y_transformed), color = "blue", size = 1.5) +
  geom_area(aes(x = x_transformed[x_transformed <= mean_new + 3.2 * sd_new], 
                y = pdf_y_transformed[x_transformed <= mean_new + 3.2 * sd_new]), fill = "lightblue") +
  labs(title = "PDF of Transformed Distribution", x = "X'", y = "Density") +
  theme_minimal()

# Create the CDF plot for the transformed distribution
cdf_plot_transformed <- ggplot() +
  geom_line(aes(x_transformed, cdf_y_transformed), color = "red", size = 1.5) +
  geom_hline(yintercept = cdf_func_transformed(mean_new + 3.2 * sd_new), linetype = "dashed", color = "black") +
  geom_vline(xintercept = mean_new + 3.2 * sd_new, linetype = "dashed", color = "black") +
  annotate("text", x = mean_new + 3.2 * sd_new, 
           y = cdf_func_transformed(mean_new + 3.2 * sd_new) +0.01, 
           label = sprintf("%.2f", round(cdf_func_transformed(mean_new + 3.2 * sd_new)),3), 
           vjust = 1, size = 5) +
  labs(title = "CDF of Transformed Distribution", x = "X'", y = "Cumulative Probability") +
  theme_minimal()

# Combine the plots
grid.arrange(pdf_plot_transformed, cdf_plot_transformed, ncol = 2)
```

Never integrate a CDF!

---
### Empirical CDF

What if we only have a sample and we don't know the true pdf?

Intuition on how it comes up:
 
```{r example40, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}
Health_data$nr=1:nrow(Health_data)

# Create the first plot: Bars of participant height by participant number
p1 <- ggplot(Health_data, aes(x = nr, y = weight)) +
  geom_segment(aes(x = nr, xend = nr, y = 0, yend = weight), color = "steelblue", size = 1.5) +
  labs(x = "Individual\nnumber", y = "Weight", title = "Individual's weight") +
  coord_flip()+
  theme_xaringan()

p1

```

```{r example401, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}

#Sort the data by weight:
Health_data_s <- Health_data[order(Health_data$weight),]
Health_data_s$nr=1:nrow(Health_data_s)

# Create the second plot: Sorted participants by height
p2 <-  ggplot(Health_data_s, aes(x = nr, y = weight)) +
  geom_segment(aes(x = nr, xend = nr, y = 0, yend = weight), color = "steelblue", size = 1.5) +
  labs(x = "Individual\nWeight Rank", y = "Weight", title = "Sorted by weight") +
  coord_flip() +
  theme_xaringan()

# Arrange the plots side by side
p2

```
---
### Empirical CDF

What if we only have a sample and we don't know the true pdf?

Intuition on how it comes up:
 
```{r example4034, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}
Health_data$nr=1:nrow(Health_data)

# Create the first plot: Bars of participant height by participant number
p1 <- ggplot(Health_data, aes(x = nr, y = weight)) +
  geom_segment(aes(x = nr, xend = nr, y = 0, yend = weight), color = "steelblue", size = 1.5) +
  labs(x = "Individual\nnumber", y = "Weight", title = "Individual's weight") +
  coord_flip()+
  theme_xaringan()

p1

```

```{r example4013, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}

#Sort the data by weight:
Health_data_s <- Health_data[order(Health_data$weight),]
Health_data_s$nr=1:nrow(Health_data_s)

rank_75kg <- Health_data_s$nr[min(which(round(Health_data_s$weight) == 75))]

# Create the second plot: Sorted participants by height with a mark for 75 kg
p2 <- ggplot(Health_data_s, aes(x = nr, y = weight)) +
  geom_segment(aes(x = nr, xend = nr, y = 0, yend = weight), color = "steelblue", size = 1.5) +
  geom_point(data = subset(Health_data_s, weight == 75), aes(x = nr, y = weight), color = "red", size = 3) +
  geom_text(aes(x = rank_75kg, y = 75, label = paste("75 kg\nRank:", rank_75kg)), hjust = -0.2, color = "red") +
  labs(x = "Individual\nWeight Rank", y = "Weight", title = "Sorted by weight") +
  coord_flip() +
  theme_xaringan()

# Arrange the plots side by side
p2

```


---
### Empirical CDF

$ECDF(x)=\frac{\sum I(w_i\leq x)}{N}=\frac{\text{Number of people with weight lower than x}}{N}$
 
<small>
- $I(w_i<x)=1$ if weight of person $i$ is lower than $x$ (*Indicator Function*)
- $N$ is total number of people (*Sample Size*)
- Share of people with weight lower than x
</small>



```{r example4b, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}
ecdf_data <- ecdf(Health_data$weight)

# Plot the cumulative distribution
cdf_plot <- ggplot(data.frame(weight = c(min(Health_data$weight), sort(Health_data$weight))), aes(x = weight)) +
  stat_ecdf(geom = "line", size = 1.5) +
  labs(title = "Cumulative Distribution Function ", x = "Weight", y = "Cumulative Probability") +
  theme_xaringan() 

# Display the plot
ggplotly(cdf_plot,
        width = 800,   # Adjust the width according to your preference
        height = 300)
```



--
- So how do we calculate share of people with weight=<50kg?

--
$P(weight\leq50)=ECDF(50)$

--
- What about more than 100?

--
$P(weight>100)=1-P(weight\leq100)=1-ECDF(100)$


---

### Empirical CDF

How to find percentiles using CDF?


```{r example4bc, echo=FALSE, fig.width=12, fig.height=3, warning=FALSE}
ecdf_data <- ecdf(Health_data$weight)

# Plot the cumulative distribution
cdf_plot <- ggplot(data.frame(weight = c(min(Health_data$weight), sort(Health_data$weight))), aes(x = weight)) +
  stat_ecdf(geom = "line", size = 1.5) +
  labs(title = "Cumulative Distribution Function ", x = "Weight", y = "Cumulative Probability") +
  theme_xaringan() 

# Display the plot
ggplotly(cdf_plot,
        width = 800,   # Adjust the width according to your preference
        height = 300)
```

- Say we are looking for 25th percentile (1st quartile.)
- call it $v_{25}$
- By definition: $P(X\leq v_{25})=25\%$
- So 1st quartile is value for which CDF is equal to 25%. 
- More generally for percentile Z: $P(X\leq v_{Z})=Z\%$


---


layout: false
class: inverse, middle


# Summarizing Data 
## Comparisions and Associations



---

##Comparisions

- Descriptive and visual comparisons

--
- NOT declaring statistically significant differences, just eyeballing

--
- That's coming next


---

###Comparing categorical variables

####Are people living in rural areas more likely to have diabetes?

- We have two categorical variables
  - Having Diabetes or not
  - Living in Rural Area or not
  
--
- We can use frequency table to see how diabetes is distributed among the two types of areas:

```{r 1, out.width='100%', fig.height=3, warning=FALSE}

Health_data$diabetes <- factor(Health_data$diabetes, levels = c(0, 1), labels = c("No", "Yes"))
Health_data$Mother_diabetes <- factor(Health_data$location_type)

# Create a frequency table
frequency_table <- table( Health_data$location_type ,Health_data$diabetes)

# Add variable names to row and column names
col_names <- c( "No Diabetes","Has Diabetes")
row_names <- c( "Rural","Urban")
rownames(frequency_table) <- row_names
colnames(frequency_table) <- col_names


table_output <- kable(frequency_table, format = "html", caption = "") %>%
  kable_styling("striped", full_width = FALSE) 

table_output 
```



---
###Comparing categorical variables

####Do people living in rural areas are more likely to have diabetes?

- Are relative frequencies more helpful?
- Share of each subgroup within the sample

```{r 2, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE, results = 'hide'}

relative_frequency_table = round(frequency_table/nrow(Health_data),2)

# Add row and column margins to the relative frequency table
relative_frequency_table_with_margins <- addmargins(relative_frequency_table, FUN = list("Total" = sum))


# Use kable() to create a table with relative frequencies and margins
table_output <- kable(relative_frequency_table_with_margins, format = "html", caption = "", digits=2) %>%
  kable_styling("striped", full_width = FALSE)


```

```{r 2a, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE}

table_output
```

--

- Can we compare numbers in the *Has Diabetes* column?

--
- **Marginal frequencies** are total probabilities by group


---


#### Table of frequency


- We want to compare whether someone living in rural area is more likely to have diabetes than someone living in urban area

--
- So we want to see whether: $$ \scriptsize P(Diabetes_i=1|Area_i=Rural)>P(Diabetes_i=1|Area_i=Urban)$$


```{r 4nfs, out.width='100%', fig.height=3.5, warning=FALSE, echo=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(patchwork)

# 1) Counts and proportions
ft <- table(Area = Health_data$location_type, Diabetes = Health_data$diabetes)
colnames(ft) <- c("No Diabetes","Has Diabetes")
rownames(ft) <- c("Rural","Urban")

counts <- as.data.frame(ft) |>
  pivot_wider(names_from = Diabetes, values_from = Freq) |>
  mutate(N     = `No Diabetes` + `Has Diabetes`,
         p_has = `Has Diabetes` / N)

# 2) Allocate a manageable number of tiles proportional to N
total_tiles_target <- 400  # adjust granularity here
counts <- counts |>
  mutate(n_tiles_area = pmax(1, round(total_tiles_target * N / sum(N))),
         tiles_has    = pmin(n_tiles_area, round(p_has * n_tiles_area)),
         tiles_no     = n_tiles_area - tiles_has)

# 3) Build tile grids
make_tiles <- function(area, tiles_has, tiles_no) {
  n_tiles <- tiles_has + tiles_no
  ncol <- ceiling(sqrt(n_tiles))
  nrow <- ceiling(n_tiles / ncol)
  tibble(
    Area   = area,
    idx    = seq_len(n_tiles),
    Status = c(rep("Has Diabetes", tiles_has), rep("No Diabetes", tiles_no))
  ) |>
    mutate(
      x = (idx - 1) %% ncol,
      y = (nrow - 1) - floor((idx - 1) / ncol),
      ncol = ncol, nrow = nrow, n_tiles = n_tiles
    )
}

tiles_rural <- make_tiles(
  "Rural",
  tiles_has = counts$tiles_has[counts$Area == "Rural"],
  tiles_no  = counts$tiles_no[counts$Area == "Rural"]
) |>
  left_join(counts |> select(Area, N, p_has), by = "Area")

tiles_urban <- make_tiles(
  "Urban",
  tiles_has = counts$tiles_has[counts$Area == "Urban"],
  tiles_no  = counts$tiles_no[counts$Area == "Urban"]
) |>
  left_join(counts |> select(Area, N, p_has), by = "Area")

# 4) Plot builders (each with coord_equal)
plot_tiles <- function(df) {
  ggplot(df, aes(x = x, y = y, fill = Status)) +
    geom_tile(width = 0.9, height = 0.9) +
    coord_equal() +
    scale_x_continuous(NULL, breaks = NULL, expand = expansion(mult = 0.02)) +
    scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = 0.02)) +
    labs(
      title    = unique(df$Area),
      subtitle = paste0(
        "N = ", comma(unique(df$N))
      ),
      fill = NULL
    ) +
    theme_minimal(base_size = 12) +
    theme(
      panel.grid = element_blank(),
      plot.title = element_text(face = "bold", hjust = 0.5),
      legend.position = "top"
    )
}

p_rural <- plot_tiles(tiles_rural)
p_urban <- plot_tiles(tiles_urban)

# 5) Combine with widths ∝ sample size (keeps coord_equal in each panel)
w_rural <- counts$N[counts$Area == "Rural"]
w_urban <- counts$N[counts$Area == "Urban"]

(p_rural + p_urban) +
  plot_layout(widths = c(w_rural, w_urban), guides = "collect") &
  theme(legend.position = "top")
```




---

#### Table of frequency


- We want to look at the **relative conditional frequencies**
- Conditional on the group they belong to. 
- Intuition: re-scale by group size and calculate number of diabetics per 100 in each group.

--
- These are usually framed as **contingency tables**
  - Share with diabetes within urban sample
  - Share with diabetes within rural sample


--
```{r 2cafd, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE}

frequency_table <- table(Health_data$location_type ,Health_data$diabetes)

# Add variable names to row and column names
col_names <- c( "No Diabetes","Has Diabetes")
row_names <- c( "Rural","Urban")
rownames(frequency_table) <- row_names
colnames(frequency_table) <- col_names

# Calculate relative frequencies
total_rows <- rowSums(frequency_table)
prop_table <- frequency_table / total_rows

table_output <-kable(prop_table, format = "html", caption = "", digits=2) %>%
  kable_styling("striped", full_width = FALSE)
table_output
```

$$ \scriptsize P(Diabetes_i=1|Area_i=Rural)=\scriptsize \frac{ P(Diabetes_i=1 \cap Area_i=Rural) }{P(Area_i=Rural)}\approx\frac{0.03}{0.03+0.24} \approx 0.1$$
Or:

$$ \scriptsize P(Diabetes_i=1|Area_i=Rural)=\scriptsize \frac{ \text{Number live in Rural & Have diabetes} }{\text{Number live in Rural}}=\frac{993}{993+8906} \approx 0.1$$

---

```{r 2ca, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE}

frequency_table <- table(Health_data$location_type ,Health_data$diabetes)

# Add variable names to row and column names
col_names <- c( "No Diabetes","Has Diabetes")
row_names <- c( "Rural","Urban")
rownames(frequency_table) <- row_names
colnames(frequency_table) <- col_names

# Calculate relative frequencies
total_rows <- rowSums(frequency_table)
prop_table <- frequency_table / total_rows

table_output <-kable(prop_table, format = "html", caption = "", digits=2) %>%
  kable_styling("striped", full_width = FALSE)
table_output
```

--
- What about marginal frequencies here?
  - Row sums should add up to 1
      - $\scriptsize P(Diabetes_i=1|\text{Area=Rural}_i)+P(Diabetes_i=0|\text{Area=Urban}_i)$
  - Column sums are meaningless
      - $\scriptsize P(Diabetes_i=1|\text{Area=Rural}_i)+P(Diabetes_i=1|\text{Area=Urban}_i)$



---
- We can visualize it on a barplot

.center[
```{r 2d, out.width='100%', fig.height=4, warning=FALSE, echo=FALSE, message=FALSE}

summary_table <- table(Health_data$location_type, Health_data$diabetes)
prop_table <- prop.table(summary_table, margin = 1)
prop_df <- as.data.frame(prop_table)

# Renaming columns for better labels
colnames(prop_df) <- c("Area", "Has Diabetes", "Proportion")


# Reshaping the dataframe for plotting



# Creating the bar plot using ggplot2
p=ggplot(prop_df, aes(x = `Has Diabetes`, y = Proportion, fill = Area)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Has Diabetes", y = "Proportion", fill = "Area") +
  theme(legend.position = "top")+
  theme_xaringan()+scale_xaringan_fill_discrete()
ggplotly(p,
        width = 800,   # Adjust the width according to your preference
        height = 400)
```
]
---

- Or better on a **stacked barplot**

.center[
```{r 2e, out.width='100%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}

summary_table <- table(Health_data$location_type, Health_data$diabetes)
prop_table <- prop.table(summary_table, margin = 1)
prop_df <- as.data.frame(prop_table)

# Renaming columns for better labels
colnames(prop_df) <- c("Area", "Has Diabetes", "Proportion")


# Reshaping the dataframe for plotting



# Creating the bar plot using ggplot2
p=ggplot(prop_df, aes(fill = `Has Diabetes`, y = Proportion, x = Area)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(x = "Area", y = "Proportion", fill = "Has Diabetes") +
  theme(legend.position = "top")+
  theme_xaringan()+scale_xaringan_fill_discrete()

ggplotly(p,
        width = 800,   # Adjust the width according to your preference
        height = 400)
```
]

- *Stacked barplot* clearly shows the distribution of diabetes within each group

---

###Practice

- Are you more likely to have diabetes if your mother had diabetes?
- By how much?

```{r 1bvc, out.width='100%', fig.height=3, warning=FALSE}
load("Data/Health_data.Rda")
Health_data$diabetes <- factor(Health_data$diabetes, levels = c(0, 1), labels = c("No", "Yes"))
Health_data$Mother_diabetes <- factor(Health_data$Mother_diabetes, levels = c(0, 1), labels = c("No", "Yes"))

# Create a frequency table
frequency_table <- table( Health_data$Mother_diabetes,Health_data$diabetes)

# Add variable names to row and column names
col_names <- c( "No Diabetes","Has Diabetes")
row_names <- c( "Mother No Diabetes","Mother Has Diabetes")
rownames(frequency_table) <- row_names
colnames(frequency_table) <- col_names


table_output <- kable(frequency_table, format = "html", caption = "") %>%
  kable_styling("striped", full_width = FALSE) 

table_output 
```


---

###Practice


```{r 2c, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE}

frequency_table <- table(Health_data$Mother_diabetes,Health_data$diabetes)

# Add variable names to row and column names
col_names <- c( "No Diabetes","Has Diabetes")
row_names <- c( "Mother No Diabetes","Mother Has Diabetes")
rownames(frequency_table) <- row_names
colnames(frequency_table) <- col_names

# Calculate relative frequencies
total_rows <- rowSums(frequency_table)
prop_table <- frequency_table / total_rows

table_output <-kable(prop_table, format = "html", caption = "", digits=2) %>%
  kable_styling("striped", full_width = FALSE)
table_output
```

- Does it mean that having diabetic mother **causes** higher change of having diabetes?

---

### One quantitative and one categorical


- For quantitative variables we can compare some summary statistics
 - Are people with diabetes older than people without it?

--
 - *Example* means in two subpopulations

```{r 2ffd, out.width='100%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}

mean_age_by_location <- Health_data %>%
  group_by(diabetes) %>%
  summarize(mean_age = mean(age))

# Reshaping the dataframe for plotting



# Creating the bar plot using ggplot2
p=ggplot(mean_age_by_location, aes(x = diabetes, y = mean_age, fill = diabetes)) +
  geom_bar(stat = "identity") +
  labs(title = "",
       x = "Diabetes",
       y = "Mean Age") +
  theme_xaringan()+scale_xaringan_fill_discrete()

ggplotly(p,
        width = 600,   # Adjust the width according to your preference
        height = 400)
```


---

### One quantitative and one categorical

- Or we can do Box and Whiskers plots as before
- Or we can compare the whole distributions of frequencies

```{r 2g, out.width='100%', fig.height=3.8, warning=FALSE, echo=FALSE, message=FALSE}

ggplot(Health_data, aes(x = age, fill = factor(diabetes))) +
  geom_bar() +
  facet_wrap(~ diabetes, ncol = 1, 
             labeller = labeller(diabetes = c("No" = "No Diabetes", "Yes" = "Diabetes")),
             scales = "free_y") +
  labs(x = "Age",
       y = "Frequency") +
  theme_xaringan()+scale_xaringan_fill_discrete()+theme(legend.position="none")
```

---
#### One quantitative and one categorical
- For continuous variables we can use the same methods (except frequency distribution) 
- Instead, we can compare densities or histograms
- Are men heavier than women?

--
.center[
```{r 2ha, out.width='100%', fig.height=3.8, warning=FALSE, echo=FALSE, message=FALSE}

ggplot(Health_data, aes(x = weight, fill=gender)) +
  geom_histogram(binwidth = 3, position = "identity", alpha = 0.7) +
  facet_wrap(~ gender, ncol = 1,
             scales = "free_y") +
  labs(
       x = "Weight",
       y = "Count") +
  theme_xaringan()+scale_xaringan_fill_discrete()+theme(legend.position="none")


```
]


---

### Associations: Two Quantitative Variables


- Likely people would subscribe to the website to lose weight

--

- But do these people have resources?

--

- What is the relationship between Body Mass Index (BMI) and Income?

--

- More generally, how to measure .blue[association between two quantitative variables]

--

- Association between qualitative variables is measured with contingency tables 

```{r 2k, out.width='100%', fig.height=3.8, warning=FALSE, echo=FALSE, message=FALSE}

# Load required library
# Load required library
set.seed(123)

# Number of observations per city
n <- 200

# Create data for Mexico City
mexico_city <- data.frame(
  City = rep("Mexico City", n),
  BMI = round(rnorm(n, mean = 24, sd = 8),2),   # Mean BMI around 25, SD = 3
  Education = round(rnorm(n, mean = 12, sd = 2.5),1),  # Mean Education around 12 years, SD = 2
  Income = round(rnorm(n, mean = 180000, sd = 10000),2)  # Mean Income around 40000, SD = 10000
)

# Create data for Guadalajara
guadalajara <- data.frame(
  City = rep("Guadalajara", n),
  BMI = round(rnorm(n, mean = 26, sd = 8),2),   # Mean BMI around 25, SD = 3
  Education = round(rnorm(n, mean = 12, sd = 2.5),1),  # Mean Education around 12 years, SD = 2
  Income = round(rnorm(n, mean = 120000, sd = 8000),2)  # Mean Income around 60000, SD = 8000
)


# Add some positive correlation to the Income and Education variables in Guadalajara
guadalajara$Income <- guadalajara$Income - 5000 * guadalajara$BMI + 16000 * guadalajara$Education
mexico_city$Income <- mexico_city$Income - 2000 * mexico_city$BMI + 16000 * mexico_city$Education



# Combine the updated Guadalajara data with Mexico City data
dataset <- rbind(mexico_city, guadalajara)


```

---
### Associations

- Suppose we surveyed people from Guadalajara and CDMX about their .blue[BMI], .blue[education] and .blue[income]. 
- Scatter plots show associations between two quantitative variables
  - We put variables of interest (*example*: Y and X) on the axis
  - We place observation on the cartesian plane using their values of variable X and Y: $\{(x_1,y_1),(x_2,y_2)..\}$
- In our case: 
    - X axis is BMI
    - Y axis is Income
    - An individual $i$ is placed on these axis based on $(BMI_i, Income_i)$


```{r 2l, out.width='95%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}
datatable(dataset,
          fillContainer = FALSE,
          options = list(
            pageLength = 4,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```


---

```{r 2z, out.width='90%', fig.height=8, warning=FALSE, echo=FALSE, message=FALSE}
p=ggplot(data = dataset, aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI", y = "Income",
       color = "City") +
  theme_xaringan()+
   geom_segment(data = dataset[100, ],
               aes(xend = BMI, yend = Income, x = BMI, y = 0), 
               linetype = "dashed", color = "blue") +
  geom_segment(data = dataset[100, ],
               aes(xend = BMI, yend = Income, x = 0, y = Income), 
               linetype = "dashed", color = "blue") +
  geom_point(data = dataset[100, ],
             aes(x = BMI, y = Income), color = "red", size = 3) +
  geom_text(data = dataset[100, ],
            aes(label = paste("(", BMI, ",", Income, ")")), 
            vjust = -1, size=7) +
  theme(legend.position = "none")

ggplotly(p,
        width = 800,   # Adjust the width according to your preference
        height = 700)

```

---
### Associations

- Scatterplots become very messy if you have a lot of observations

```{r 2za, out.width='90%', fig.height=4, warning=FALSE, echo=FALSE, message=FALSE}

set.seed(123)

# Number of observations per city
n <- 5000

# Create data for Mexico City
mexico_city <- data.frame(
  City = rep("Mexico City", n),
  BMI = round(rnorm(n, mean = 24, sd = 8),2),   # Mean BMI around 25, SD = 3
  Education = round(rnorm(n, mean = 12, sd = 2.5),1),  # Mean Education around 12 years, SD = 2
  Income = round(rnorm(n, mean = 180000, sd = 10000),2)  # Mean Income around 40000, SD = 10000
)

# Create data for Guadalajara
guadalajara <- data.frame(
  City = rep("Guadalajara", n),
  BMI = round(rnorm(n, mean = 26, sd = 8),2),   # Mean BMI around 25, SD = 3
  Education = round(rnorm(n, mean = 12, sd = 2.5),1),  # Mean Education around 12 years, SD = 2
  Income = round(rnorm(n, mean = 120000, sd = 8000),2)  # Mean Income around 60000, SD = 8000
)


# Add some positive correlation to the Income and Education variables in Guadalajara
guadalajara$Income <- guadalajara$Income - 5000 * guadalajara$BMI + 16000 * guadalajara$Education
mexico_city$Income <- mexico_city$Income - 2000 * mexico_city$BMI + 16000 * mexico_city$Education



# Combine the updated Guadalajara data with Mexico City data
dataset2 <- rbind(mexico_city, guadalajara)

p=ggplot(data = dataset2, aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI", y = "Income",
       color = "City") +
  theme_xaringan()+
   geom_segment(data = dataset[100, ],
               aes(xend = BMI, yend = Income, x = BMI, y = 0), 
               linetype = "dashed", color = "blue") +
  geom_segment(data = dataset[100, ],
               aes(xend = BMI, yend = Income, x = 0, y = Income), 
               linetype = "dashed", color = "blue") +
  geom_point(data = dataset[100, ],
             aes(x = BMI, y = Income), color = "red", size = 3) +
  geom_text(data = dataset[100, ],
            aes(label = paste("(", BMI, ",", Income, ")")), 
            vjust = -1, size=7) +
  theme(legend.position = "none")

ggplotly(p,
        width = 500,   # Adjust the width according to your preference
        height = 500)

```
---

### Associations

- If n is larger, better to use binscatter: 
  - Group x variable into quantiles (ex: 10 deciles)
  - Calculate average of y in each decile
  - Plot

```{r 2zf, out.width='90%', fig.height=4, warning=FALSE, echo=FALSE, message=FALSE}

library(binsreg)

binsreg(x=dataset2$BMI, y=dataset2$Income, nbins=10)


```
---


### Assocations

- Would you say that the relationship is stronger in Guadalajara or in Mexico City?

```{r 2h, out.width='80%', fig.height=4, warning=FALSE, echo=FALSE, message=FALSE}
ggplot(data = dataset, aes(x = BMI, y = Income, color = City)) +
  geom_point() +
  labs(x = "BMI", y = "Income",
       color = "City") +
  theme_xaringan()+
  facet_wrap(~City)+
  theme(legend.position = "none")
```

- How to measure the strength of the relationship?

---
### Associations
#### Covariance

- **Covariance** measures the strength of the relationship between two variables. 

$$\text{Cov}(X, Y) = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_X)(y_i - \mu_Y)$$

And it's sample equivalent is: 

$$\hat{\text{Cov}}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})$$
--
- Covariance whether the two variables move together

--
- Covariance increases when:
  - The relationship is stronger
  - The deviations of variables are larger


---

`r knitr::include_url('https://shiny.rit.albany.edu/stat/rectangles/', height='550px')`

.footmark[
  Source: [https://shiny.rit.albany.edu/stat/rectangles/](https://shiny.rit.albany.edu/stat/rectangles/)
]

---
### Covariance

```{r 2zz, out.width='100%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}

# Calculate covariances for each city
cov_mexico <- cov(dataset$BMI[dataset$City == "Mexico City"], dataset$Income[dataset$City == "Mexico City"])
cov_guadalajara <- cov(dataset$BMI[dataset$City == "Guadalajara"], dataset$Income[dataset$City == "Guadalajara"])

# Create individual plots with annotations
plot_mexico <- ggplot(data = subset(dataset, City == "Mexico City"), aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI CDMX", y = "Income") +
  annotate("text", x = 27, y = 0, label = paste("Cov:", round(cov_mexico, 2)), color = "blue")+
  theme_xaringan()+
  xlim(0,50)+ylim(-100000,400000)
  

plot_guadalajara <- ggplot(data = subset(dataset, City == "Guadalajara"), aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI GDL", y = "") +
  annotate("text", x = 27, y = 0, label = paste("Cov:", round(cov_guadalajara, 2)), color = "red")+
  theme_xaringan()+
  xlim(0,50)+ylim(-100000,400000)

# Combine the plots using patchwork
combined_plot <- plot_mexico + plot_guadalajara +
  plot_layout(ncol = 2, widths = c(1, 1.2))

# Display the combined plot
print(combined_plot)
```

---
### Covariance

- What has stronger relationship with Income: BMI or Years of Education?

```{r 2zzza, out.width='100%', fig.height=3, warning=FALSE, echo=FALSE, message=FALSE}

# Calculate covariances for each city
cov_mexico <- cov(dataset$Education, dataset$Income)
cov_guadalajara <- cov(dataset$BMI, dataset$Income)

# Create individual plots with annotations for covariances
plot_education <- ggplot(data = dataset, aes(x = Education, y = Income)) +
  geom_point() +
  labs(x = "Yrs of Educ.", y = "Income") +
  geom_text(data = data.frame(x = 30, y = 0, label = paste("Cov (Education):", round(cov_mexico, 2))), aes(x, y, label = label), color = "blue") +
  theme_xaringan()+
  xlim(0,50)

plot_bmi <- ggplot(data = dataset, aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI", y = "") +
  geom_text(data = data.frame(x = 30, y = 0, label = paste("Cov (BMI):", round(cov_guadalajara, 2))), aes(x, y, label = label), color = "red")+
  theme_xaringan()+
  xlim(0,50)

# Combine the plots using patchwork
combined_plot <- plot_education + plot_bmi +
  plot_layout(ncol = 2, widths = c(1, 1))

# Display the combined plot
print(combined_plot)

```

- BMI has larger covariance

--
- But we can't compare covariances of different variables

--
- Covariance depends on the scales (or units) of the variable

--
- All else equal, larger standard deviation implies larger covariance
  - The squares are just bigger


---
### Reminder

We often use it to calculate variance of a sum or difference of two random variables

$$Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$$

$$Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y)$$

Reminder: if a is a constant
$$E(aX)=aE(X) \quad and \quad E(a+X)=E(X)+a$$
And 
$$E(X+Y)=E(X)+E(Y)$$

More on that in the homework!

---
### Correlation

- **Correlation measures** the strength of a linear relationship between two variables.
- It ranges between -1 and 1 

**Population Correlation coefficient**:
$$\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \cdot \sigma_Y}$$


**Sample Correlation coefficient**:

$$\hat{\rho}(X, Y) = \frac{\hat{\text{Cov}}(X, Y)}{s_X \cdot s_Y}$$
Where $s_X = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}$


---
### Correlation

- Correlation is preferred over covariance because it's **scale-independent** and easier to interpret.
- Suppose that instead of measuring income (Y variable) in MXN , we measure it in Dollars. 
 - $Z$ income in dollars $Z=\frac{Y}{16}$
 
--
- Is $Cov(X,Z)=Cov(X,Y)$?

\begin{align*}
cov(X,Z) &=\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_X)(z_i - \mu_Z) \\
&=\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_X)(\frac{y_i}{16}- \frac{\mu_Y}{16}) \\
&=\frac{1}{16}\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_X)(y_i- \mu_Y) \\
& \neq cov(X,Y)
\end{align*}


---
### Correlation

- Correlation is preferred over covariance because it's **scale-independent** and easier to interpret.

- Suppose that instead of measuring income (Y variable) in MXN , we measure it in Dollars. 
 - $Z$ income in dollars $Z=\frac{Y}{16}$
 
--
- Is $\rho(X,Z)=\rho(X,Y)$?



\begin{align*}
\rho(X,Z) &=\frac{\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_X)(z_i - \mu_Z))}{\sqrt{\sum_{i=1}^{N} (x_i - \mu_X)^2} \cdot \sqrt{\sum_{i=1}^{N} (z_i - \mu_Z)^2}} \\
&=\frac{\frac{1}{N} \sum_{i=1}^{N} \sum_{i=1}^{N} (x_i - \mu_X)(\frac{y_i}{16}- \frac{\mu_Y}{16})}{\sqrt{\sum_{i=1}^{N} (x_i - \mu_X)^2} \cdot \sqrt{\sum_{i=1}^{N} (\frac{y_i}{16} - \frac{\mu_Y}{16})^2}} \\
&=\frac{\frac{1}{16} \frac{1}{N} \sum_{i=1}^{N} \sum_{i=1}^{N} (x_i - \mu_X)(y_i- \mu_Y)}{\frac{1}{16} \sqrt{\sum_{i=1}^{N} (x_i - \mu_X)^2} \cdot \sqrt{\sum_{i=1}^{N} (y_i - \mu_Y)^2}} \\
& = \rho(X,Y)
\end{align*}


---
### Correlation

- Correlation with education is actually stronger

```{r 2zzz, out.width='100%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}

# Calculate covariances for each city
cov_mexico <- cor(dataset$Education, dataset$Income)
cov_guadalajara <- cor(dataset$BMI, dataset$Income)

# Create individual plots with annotations for covariances
plot_education <- ggplot(data = dataset, aes(x = Education, y = Income)) +
  geom_point() +
  labs(x = "Yrs of Educ.", y = "Income") +
  geom_text(data = data.frame(x = 30, y = -100000, label = paste("Cor (Education):", round(cov_mexico, 2))), aes(x, y, label = label), color = "blue") +
  theme_xaringan()+
  xlim(0,50)

plot_bmi <- ggplot(data = dataset, aes(x = BMI, y = Income)) +
  geom_point() +
  labs(x = "BMI", y = "") +
  geom_text(data = data.frame(x = 30, y = -100000, label = paste("Cor (BMI):", round(cov_guadalajara, 2))), aes(x, y, label = label), color = "red")+
  theme_xaringan()+
  xlim(0,50)

# Combine the plots using patchwork
combined_plot <- plot_education + plot_bmi +
  plot_layout(ncol = 2, widths = c(1, 1))

# Display the combined plot
print(combined_plot)

```



---
```{r 2zzzz, out.width='100%', fig.height=5, warning=FALSE, echo=FALSE, message=FALSE}

library(plotly)

# Set random seed for reproducibility
set.seed(123)

# Generate data
n <- 100

xlim <- c(-4, 4)
ylim <- c(-8, 8)

# Positive correlation
x1 <- rnorm(n)
y1 <- x1 + rnorm(n)
plot1 <- plot_ly(x = x1, y = y1, text = paste("correlation:",round(cor(x1, y1), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 200,   # Adjust the width according to your preference
        height = 200)

# Negative correlation

# Negative correlation
x2 <- rnorm(n)
y2 <- -x2 + rnorm(n)
plot2 <- plot_ly(x = x2, y = y2, text = paste("correlation:", round(cor(x2, y2), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 200,   # Adjust the width according to your preference
        height = 200)

# Negative correlation

# No correlation
x3 <- rnorm(n)
y3 <- rnorm(n)
plot3 <- plot_ly(x = x3, y = y3, text = paste("correlation:",round(cor(x3, y3), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 800,   # Adjust the width according to your preference
        height = 400)

# Negative correlation

x_base <- rnorm(n)
y_base <- x_base + rnorm(n)

cor_base <- cor(x_base, y_base)

# Create the first plot with slope 2 by scaling the base relationship
x4 <- x_base
y4 <- 2 * y_base
plot4 <- plot_ly(x = x4, y = y4, text = paste("correlation:",round(cor(x4, y4), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 800,   # Adjust the width according to your preference
        height = 400)

# Negative correlation

# Create the second plot with slope 0.5 by scaling the base relationship
x5 <- 2 * x_base
y5 <- y_base
plot5 <- plot_ly(x = x5, y = y5, text = paste("correlation:",round(cor(x5, y5), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 800,   # Adjust the width according to your preference
        height = 400)

# Negative correlation

# Non-linear relationship with near zero correlation
x6 <- seq(-2*pi, 2*pi, length.out = n)
y6 <- sin(x6) + rnorm(n, sd=0.5)
plot6 <- plot_ly(x = x6, y = y6, text = paste("correlation:",round(cor(x6, y6), 2)), type = 'scatter', mode = 'markers', showlegend = FALSE)%>%
layout(xaxis = list(range = xlim), yaxis = list(range = ylim),
        width = 800,   # Adjust the width according to your preference
        height = 400)

# Negative correlation

# Combine plots into a single plot with multiple subplots (in 2 rows)
subplot(plot1, plot2, plot3, plot4, plot5, plot6, nrows = 2, margin = 0.02)

```

---
### Correlation

1. Correlation is a value between -1 and 1: $-1 \leq \rho(X, Y) \leq 1$.

--
2. Perfect positive correlation: $\rho = 1$. Perfect negative correlation: $\rho = -1$.

--
3. No linear correlation: $\rho = 0$, but this doesn't imply independence.

--
4. Correlation measures **linear** relationships; nonlinear relationships might not be accurately captured.

--
5. Correlation doesn't imply causation; a relationship could be coincidental.

---

### Causality vs Correlation


<center>
<img src=Trump.jpg width="800">
</center>


---
### Causality vs Correlation

`r knitr::include_url('https://tylervigen.com/spurious-correlations', height='550px')`

.footmark[
  Source: [https://tylervigen.com/spurious-correlations](https://tylervigen.com/spurious-correlations)
]



---
### Causality vs Correlation
- Less obvious examples
- You look at historical data from some media campaign
- You notice that people who were more exposed to ads were less likely to buy that product
- What can you conclude?

--
- Are people who were exposed to ads similar to people who were not?

--
- Maybe they were targeted in the first place because they are less likely to buy and you want to change it?


---
### Causality vs Correlation
- Less obvious examples
- Education usually correlates with Income (correlation)

- Does it mean that if decide to get a degree, you will earn more? (causality)


