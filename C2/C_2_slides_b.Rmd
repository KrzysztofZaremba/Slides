---
title: 'Class 2b: Review of concepts in Probability and Statistics'
author: "Business Forecasting"
output:
  xaringan::moon_reader:
    self_contained: true
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: true
      fig.retina: 2
---   
<style type="text/css">
.remark-slide-content {
    font-size: 20px;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,dpi=300)
library(shiny)
library(ggplot2)
library(forecast)
library(plotly)
library(dplyr)
library(igraph)
library(reshape)
library(spData)
library(leaflet)
library(readr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(hrbrthemes)
library(viridis)
library(gapminder)
library(knitr)
library(kableExtra)
library(DT)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(base_color = "#43418A", 
colors = c(
  red = "#f34213",
  purple = "#3e2f5b",
  orange = "#ff8811",
  green = "#136f63",
  blue = "#1E90FF",
  white = "#FFFFFF"
))
```


```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(dplyr)
load("Data/Health_data.Rda")

```

---

layout: false
class: inverse, middle


# Summarizing Data 

## Summary Statistics

---
# Measures of Central Tendency
## Mean

- **Mean** represents the arithmetic average of the data.
- Sometimes called the expected value of the random variable E(X)
- The population mean $\mu$ is the sum of all observations divided by the total population size:

$$\mu =E(X)=\frac{\sum_{i=1}^{N} x_i}{N}=\sum_{x\in X}P(X=x) \times x$$

- where $N$ is the total population size, and $x_i$ are individual data points.

- The sample mean, denoted as $\bar{x}$, is the sample equivalent:

$$\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n} = \frac{x_1+x_2+...x_{n-1}+x_n}{n}$$

where $n$ is the sample size.



---
## Mean

Intuitively, mean is the balancing point of the distribution. 

```{r, warning=FALSE, fig.height=4.5}
# Load necessary libraries
# Load necessary libraries
library(ggplot2)

# Create a sample dataset with positive and negative values
set.seed(42)
sample_data <- c(rnorm(200, mean = -20, sd = 10), rnorm(200, mean = 25, sd = 30))

# Calculate the sample mean
sample_mean <- mean(sample_data)

# Create a data frame for the plot
df <- data.frame(Value = sample_data)

# Create the plot
ggplot(df, aes(x = Value)) +
  geom_histogram(binwidth = 3) +
  geom_vline(xintercept = sample_mean, linetype = "dashed", color = "grey", size = 1.5) +
  labs(title = "",
       x = "Values", y = "Frequency") +
  theme_xaringan() +
  theme(legend.position = "none")
```

---
## Mean of a binary variable

What if a mean of a **binary variable**?
  - Binary variable is a variable which takes value 0 or 1
  - For example: do you have diabetes (yes=1, no=0)
  
--

What is the intuitive interpretation of the mean of this variable?

  - $\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}$
  - $\bar{x} = \frac{1+0+0+...0+1}{n}=\frac{n_{diabetes}}{n}=\hat{\mu}_{diabetes}$
  
--

It's the proportion of people with diabetes in the sample: mean(diabetes)= `r format(round(mean(Health_data$diabetes),3), scientific=FALSE)`

---


## Weighted Mean

- In some scenarios, data points have different weights. 
- For a dataset with weights $w_i$ and values $x_i$, the weighted mean is:

$$\small \text{Weighted Mean} = \frac{\sum_{i=1}^{n} w_i \cdot x_i}{\sum_{i=1}^{n} w_i}$$
```{r, echo=FALSE, results='asis'}
# Create a data frame for the table
df <- data.frame(Person = c("Midterm 1", "Midterm 2", "Quizzes", "Final Project", "Final exam"),
                 Weight = c(0.2, 0.2, 0.15, 0.15, 0.3),
                 Grade = c(6, 8, 9, 4, 8))

# Display the data in a table
datatable(df,
          fillContainer = FALSE,
          options = list(
            pageLength = 4,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```



The ** weighted mean** is:

\begin{align*}
\small
    \bar{x} & =\frac{0.2\times 6+0.2\times 8+0.15 \times  9+ 0.15 \times  4+0.3 \times 8}{0.2+0.2+0.15+0.15+0.3} 
\end{align*}


---
## Mean

- Is mean always a right measure?

#### "Bill Gates walks into a bar"

- Suppose a group of people, including Bill Gates, walks into a bar.
- Let's say the net worth of everyone in the group is as follows:

.pull-left[
```{r, echo=FALSE, results='asis'}
# Create a data frame for the table
df <- data.frame(Person = c("Person 1", "Person 2", "Person 3", "Person 4", "Person 5", "Bill Gates"),
                 Net_Worth = c(10, 20, 30, 40, 50, 600000))

# Display the data in a table
datatable(df,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE
)
```
]

.pull-right[
The **mean** is:

\begin{align*}
    \bar{x} & =\frac{10 + 20 + 30 + 40 + 50 + 60000}{6} \\
    & = 10025 \\
\end{align*}


Mean is seriously skewed due to the outlier.
]

---

## Mean vs Median

<center>
<img src=mean_median.jpg width="800">
</center>

---
## Median

- **Median** represents the middle value when data is sorted
- Half of observations are below it, half are above it.
- For a dataset with odd size $n$, the median is the $\frac{n+1}{2}$-th value
- For even size $n$, it's the average of $\frac{n}{2}$-th and $\frac{n}{2}+1$-th values.

.pull-left[
| Day | Number of Customers |
|-----|---------------------|
| 1   | 20                  |
| 2   | 18                  |
| 3   | 25                  |
| 4   | 22                  |
| 5   | 30                  |
| 6   | 21                  |
| 7   | 27                  |
]

.pull-right[
The dataset has $n=7$ (odd) observations, so to find the median:

- Arrange the data in ascending order:
    - 18, 20, 21, 22, 25, 27, 30.
- The median is the $\frac{n+1}{2}$-th value, which is the 4th value.
- Thus, the median is the 4th value, which is 22.
]

---

### Let's look at the median weight in our population
```{r, warning=FALSE, fig.height=5, echo=FALSE}
mean_weight_original <- mean(Health_data$weight)
median_weight_original <- median(Health_data$weight)
```
- Mean: `r format(mean_weight_original, scientific=FALSE)`
- Median: `r format(median_weight_original, scientific=FALSE)`

--

```{r, warning=FALSE, fig.height=4, out.width='100%'}
# Load the required libraries


# Calculate the mean and median of the original weight variable


# Create a histogram of the weight variable with extreme values
ggplot(Health_data, aes(x = weight)) +
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black") +
  labs(title = "", x = "Weight", y = "Frequency") +
  theme_xaringan() +
  theme(plot.title = element_text(hjust = 0.5)) +
  # Add vertical lines for mean and median of original data
  geom_vline(xintercept = mean_weight_original, color = "red", linetype = "dotted", size = 2) +
  geom_vline(xintercept = median_weight_original, color = "blue", linetype = "dashed", size = 2)
  # Add labels for mean and median of original data

# Add some extreme values to the right of the weight distribution
extreme_values <- rep(c(290, 300, 305, 315, 320, 330, 340),100)
Health_data_with_extremes <- c(Health_data$weight, extreme_values)

# Calculate the mean and median of the weight variable with extreme values
mean_weight_extremes <- mean(Health_data_with_extremes)
median_weight_extremes <- median(Health_data_with_extremes)



```
- Mean is dotted
- Median is dashed
---

### Median and outliers

I added couple of observations on the right tail of the distribution

- Old Mean: `r format(round(mean_weight_original,2), scientific=FALSE)`, **New Mean: `r format(round(mean_weight_extremes,2), scientific=FALSE)`**
- Old Median: `r format(round(median_weight_original,2), scientific=FALSE)`, **New Median:  `r format(round(median_weight_extremes,2), scientific=FALSE)`**


```{r abc, warning=FALSE, fig.height=4, out.width='100%'}
# Load the required libraries
library(ggplot2)



# Create a histogram of the weight variable with extreme values
ggplot(data.frame(weight = Health_data_with_extremes), aes(x = weight)) +
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black") +
  labs(title = "", x = "Weight", y = "Frequency") +
  theme_xaringan() +
  theme(plot.title = element_text(hjust = 0.5)) +
  # Add vertical lines for mean and median of original data
  geom_vline(xintercept = mean_weight_original, color = "red", linetype = "dotted", size = 2) +
  geom_vline(xintercept = median_weight_original, color = "blue", linetype = "dashed", size = 2) +
  # Add vertical lines for mean and median with extreme values
  geom_vline(xintercept = mean_weight_extremes, color = "orange", linetype = "dotted", size = 2) +
  geom_vline(xintercept = median_weight_extremes, color = "Green", linetype = "dashed", size = 2) 
  # Add labels for mean and median of original data
  # Add labels for mean and median with extreme values

```


---

## Side note on the Mode

**Mode** is the most frequent value in the data

- Let's look at the distribution of age of people with diabtese
```{r, out.width='100%', fig.height=4, warning=FALSE}
frequency_table <- table(Health_data[Health_data$diabetes==1,]$age)
frequency_table <- as.data.frame(frequency_table)
colnames(frequency_table) <- c('Age', 'n_i')

# Adding relative frequencies (p_i)
frequency_table$p_i <- prop.table(frequency_table$n_i)
frequency_table$p_i <- round(prop.table(frequency_table$n_i), 3)

datatable(frequency_table,
          fillContainer = FALSE,
          options = list(
            pageLength = 6,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE)

```



---

## Mode

<center>
<img src=mode.jpg width="400">
</center>

---
## Percentiles


<center>
<img src=Natalie.jpg width="300">
</center>


---

## Percentiles


<center>
<img src=t_swift2.jpg width="300">
</center>

---

## Percentiles


<center>
<img src=t_swift_01.jpg width="300">
</center>

---



---

## Percentiles



<center>
<img src=t_swift_0001.jpg width="300">
</center>



---

## Percentiles



<center>
<img src=WSJ.jpg width="800">
</center>

Credits: Wall Street Journal
[Article Link](https://www.wsj.com/tech/personal-tech/spotify-wrapped-2023-taylor-swift-e303333d)

---
## Percentiles

- How much inventory of milk you need to keep in your Starbucks?

--
- What is the tradeoff of keeping too much vs too litle inventory?

--
- Suppose we want to have enough of milk to cover sales on 95% of days

--
- To figure it out, let's look at the distribution of the daily use of milk

```{r Sales_dist_figure, out.width='100%', fig.height=3, warning=FALSE}

# Set seed for reproducibility
set.seed(42)

# Generate sample data for daily milk sales (right-skewed gamma distribution)
shape_param <- 5  # Shape parameter for the gamma distribution
scale_param <- 30  # Scale parameter for the gamma distribution
num_samples <- 1000
daily_sales_data <- rgamma(num_samples, shape = shape_param, scale = scale_param)

# Calculate the desired inventory level to avoid stockouts on at least 95% of days
desired_service_level <- 0.95
optimal_inventory_level <- qgamma(desired_service_level, shape = shape_param, scale = scale_param)

# Calculate the stockout probability
stockout_probability <- sum(daily_sales_data < optimal_inventory_level) / num_samples

# Create a data frame for the histogram
hist_data <- data.frame(DailySales = daily_sales_data)

# Create the ggplot figure
ggplot(hist_data, aes(x = DailySales)) +
  geom_histogram(aes(y = after_stat(count / sum(count))), bins = 30, fill = "lightblue", color = "black") +
  labs(title = "",
       x = "Daily Use of Milk",
       y = "Relative frequency") +
  theme_xaringan()
```


---

## Percentiles

- Let $s_i$ be the daily sales of milk
- We want to choose amount $M$, such that $P(s_i \leq M)=0.95$
- That is, in 95% of days sales are smaller or equal than $M$

--
```{r Sales_dist_figure_with_shaded_region, out.width='100%', fig.height=3, warning=FALSE}
hist_data$up=hist_data$DailySales<optimal_inventory_level

ggplot(hist_data, aes(x = DailySales, fill = after_stat(x) > optimal_inventory_level)) +
  geom_histogram(aes(y = after_stat(count / sum(count))), bins = 30, color = "black") +
  geom_vline(xintercept = optimal_inventory_level, color = "red", linetype = "dashed", size = 1) +
  scale_fill_manual(values = c("red", "lightblue")) +
  geom_text(aes(x = optimal_inventory_level * 0.5, y = 0.005, label = "95%"), color = "white", size = 5) +
  labs(title = "",
       x = "Daily Milk Use",
       y = "Relative frequency") +
  theme(legend.position = "none")+
  theme_xaringan()

```

--

- What is this number? 
- It's the 95th percentile of the distribution (274 liters)

---
## Percentiles

- *Percentiles* divide the ordered data into 100 equal parts. 
- $p$th percentile is a value such that $p\%$ of the data are below it
    - $v_p$ is such that $P(x_i \leq v_p)=p$
    - $v_{95}$ is such that $P(x_i \leq v_{95})=95\%$

---
## Percentiles

--

- What is the the height such that 75% of ITAM students are smaller than this height?

--

- What is the income level such that 25% of people in Mexico earn less than that level?

--

- What is the age, such that 50% of people die before that age?




---

## How to find it in a sample
1. Arrange the data in ascending order

--
2. Find which observation corresponds to the relevant percentile
  - Formula: $i = \left(\frac{p}{100}\right)(n+1)$
  - Example: To find 95th percentile in a sample of 1000 observations we look at $i = \left(\frac{95}{100}\right)(1000+1)=950.95$ observation
  
--

3. If it's an integer, value of ith observation is your percentile
4. If it's not, take the average between ith rounded down and ith rounded up 
    - In our example it would be the average of 950th and 951th observation
 
 
 --

## Or use the CDF

- $ECDF(v)=P(x_i \leq v)$

```{r Image_of _CDF, out.width='100%', fig.height=3, warning=FALSE}
ecdf_data <- ecdf(Health_data$weight)

# Plot the cumulative distribution
cdf_plot <- ggplot(data.frame(weight = c(min(Health_data$weight), sort(Health_data$weight))), aes(x = weight)) +
stat_ecdf(geom = "line", size = 1.5) +
  labs(title = "Cumulative Distribution Function ", x = "Weight", y = "Cumulative Probability") +
  theme_xaringan() 

# Display the plot
ggplotly(cdf_plot,
        width = 800,   # Adjust the width according to your preference
        height = 300)

```
---
## Common values

- **Median** - 50th percentile - half of the values are below the median

- **Quartiles** - 25th, 50th and 75th percentile. 
  - How poor is the poorest quartile of the society? 
  - Their income is below the 25th percentile
  
```{r Image_with_shaded_area_Qtiles, out.width='100%', fig.height=3, warning=FALSE}
# Generate sample data for income distribution (assuming a normal distribution)

# Define the mean and standard deviation
mean <- 20000
std_dev <- 2000

# Calculate the 1st quartile (25th percentile)
q1 <- qnorm(0.25, mean = mean, sd = std_dev)

# Create the ggplot figure
ggplot(data.frame(x = c(0, 40000)), aes(x)) +
  stat_function(fun = dnorm,
                geom = "area",
                fill = "steelblue",
                xlim = c(0, 18461.66),
                args = list(
                  mean = mean,
                  sd = std_dev
                )) +
  stat_function(fun = dnorm,
                geom = "line",
                xlim = c(18461.66, 40000),
                args = list(
                  mean = mean,
                  sd = std_dev
                )) +
  geom_vline(xintercept = q1, color = "red", linetype = "dashed") +
  annotate("text", x = q1, y = 0.00008, label = "18461.66", color = "red", angle = 90) +
  annotate("text", x = 13000, y = 0.00005, label = "25%", color = "black") +
  xlim(0, 40000) +
  labs(y="frequency", x="income")+
  theme_xaringan()


```

---

- **Deciles** - 10th, 20th, ... 90th 
  - How bad pollution gets in CDMX during top 10% polluted days?
  - During top 10% of polluted days pollution level is larger or than 9th decile.  
  
```{r Image_with_shaded_area_Deciles, out.width='100%', fig.height=4, warning=FALSE}
library(ggplot2)

# Generate sample data for daily pollution (using a normal distribution as an example)
set.seed(42)
mean_pollution <- 25  # WHO guideline for annual mean PM2.5
std_dev_pollution <- 5  # Standard deviation of pollution (adjust as needed)
num_days <- 365  # Number of days
pollution_data <- rnorm(num_days, mean = mean_pollution, sd = std_dev_pollution)

# Calculate the 90th percentile (top 10% polluted days)
pct_90 <- quantile(pollution_data, probs = 0.9)

# Create the ggplot figure
ggplot(data.frame(x = c(0, 50)), aes(x)) +
  stat_function(fun = dnorm,
                args = list(mean = mean_pollution, sd = std_dev_pollution),
                geom = "area",
                fill = "steelblue",
                xlim = c(0, pct_90)) +
  stat_function(fun = dnorm,
                args = list(mean = mean_pollution, sd = std_dev_pollution),
                geom = "line",
                xlim = c(pct_90, 50)) +
  geom_vline(xintercept = pct_90, color = "red", linetype = "dashed") +
  annotate("text", x = pct_90 - 2.5, y = 0.02, label = paste0(round(pct_90, 1), " μg/m³"),
           color = "red", angle = 90, size = 4) +
  annotate("text", x = 20, y = 0.005, label = "90% of Days",
           color = "black", size = 5) +
  xlim(0, 50) +
  xlab("PM2.5")+
  ylab("frequency")+
  theme_xaringan()


```

---

### Example with data

Here is a data on distribution of how many views have various tik-tok videos. 
- What is the 1st decile?
- What is the 95th percentile?

```{r, out.width='100%', fig.height=4, warning=FALSE}
# Set the seed for reproducibility
set.seed(42)

# Number of observations
num_observations <- 200

# Generate synthetic data for views (lognormal distribution with long right tail)
views <- round(rlnorm(num_observations, meanlog = 10, sdlog = 1.5))

# Generate video names
video_names <- paste("TikTok Video", 1:num_observations)

# Create the dataset
tiktok_dataset <- data.frame(VideoTitle = video_names, Views = views)
datatable(tiktok_dataset,
          fillContainer = FALSE,
          options = list(
            pageLength = 4,
            searching = FALSE,
            initComplete = JS(
              "function(settings, json) {",
              "$(this.api().table().container()).css({'font-size': '12px'});",
              "}"
            )
          ),
          rownames = FALSE)

```

--

- Index for the first decile is: $i = \left(\frac{10}{100}\right)(200+1)=20.1$
  - First decile is the average of the 20th and 21st observation
- Index for the 95th percentile is: $i = \left(\frac{95}{100}\right)(200+1)=190.95$
  - 95th percentile is the average of the at 190th and 191st observation


---
## Percentiles


<center>
<img src=Exam_q_top5.png width="800">
</center>



---
### Exercises:

- Review Exercises:
  - PDF 2: 3,4,5,6,

- Homeworks
  - Lista 00.1: 3

